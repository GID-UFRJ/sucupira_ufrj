{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644259b1-169d-4bba-ac04-89d6e7f6fddb",
   "metadata": {},
   "source": [
    "# Dados abertos CAPES - Modelagem para painel do GID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8614e75e-d2cc-4e3b-be08-20e2c61389e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando bibliotecas necessárias:\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import ssl\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13bc52b7-38eb-4959-8988-1e5fcf915b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diretórios usados para armazenar os dados (baixados e processados)\n",
    "dirs = {\n",
    "    'download_dir': 'capes_csv_files',\n",
    "    'filtered_dir': 'ufrj_data',\n",
    "    'processed_dir': 'sucupira_painel',\n",
    "    'discentes': 'discentes',\n",
    "    'docentes': 'docentes',\n",
    "    'programas': 'programas',\n",
    "    'cursos':  'programas',\n",
    "    'producao': 'producao',\n",
    "    'producao_detalhe': 'producao',\n",
    "    'producao_autor': 'producao',\n",
    "    'projetos': 'projetos',\n",
    "    'membros': 'projetos',\n",
    "    'financiadores': 'financiadores',\n",
    "    'btd': 'btd',\n",
    "}\n",
    "\n",
    "#Base directories\n",
    "download_dir = dirs.get('download_dir')\n",
    "filtered_dir = dirs.get('filtered_dir')\n",
    "processed_dir = dirs.get('processed_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7410c680-8b60-46da-8e69-788b991ae480",
   "metadata": {},
   "source": [
    "## Download dos dados abertos da CAPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2295f16-1fd3-4fee-a5e2-eb7a3a84e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações do download\n",
    "api_url = \"https://dadosabertos.capes.gov.br/api/3/action/package_search\"\n",
    "organization = \"diretoria-de-avaliacao\"\n",
    "output_dir = dirs.get('download_dir', 'capes_csv_files')\n",
    "timeout_seconds = 30\n",
    "max_retries = 3\n",
    "\n",
    "\n",
    "prefix_substring_dirs = {\n",
    "    \"ddi-br-capes-colsucup-\": {\n",
    "        \"projeto-financiador\": dirs.get(\"financiadores\", \"financiadores\"),\n",
    "        \"projeto\": dirs.get(\"projetos\", \"projetos\"),\n",
    "    }, \n",
    "    \"br-capes-colsucup-\": {\n",
    "        \"prod\": dirs.get(\"producao\", \"producao\"),\n",
    "        \"producao\": dirs.get(\"producao\", \"producao\"),\n",
    "        \"projeto\": dirs.get(\"projetos\", \"projetos\"),\n",
    "        \"membro\": dirs.get(\"projetos\", \"projetos\"),\n",
    "        \"prog\": dirs.get(\"programas\", \"programas\"),\n",
    "        \"curso\": dirs.get(\"cursos\", \"cursos\"),\n",
    "\t\t\"discentes\": dirs.get(\"discentes\", \"discentes\"),\n",
    "\t\t\"docente\": dirs.get(\"docentes\", \"docentes\"),\n",
    "        \"financiador\": dirs.get(\"financiadores\", \"financiadores\"),\n",
    "    },\n",
    "    \"br-capes-col-\": {\n",
    "        \"proj\": dirs.get(\"projetos\", \"projetos\"),\n",
    "        \"producao\": dirs.get(\"producao\", \"producao\"),\n",
    "        \"prod\": dirs.get(\"producao\", \"producao\"),\n",
    "    },\n",
    "\t\"br-colsucup-\": {\n",
    "\t\t\"prod\": dirs.get(\"producao\", \"producao\"),\n",
    "\t},\n",
    "    \"br-capes-btd-\": {\n",
    "        \"\": dirs.get(\"btd\", \"btd\")\n",
    "    },\n",
    "} # Mapeia prefix+substring para pastas (diretórios)\n",
    "\n",
    "# Sessão com retry\n",
    "session = requests.Session()\n",
    "retry = Retry(total=max_retries, backoff_factor=1)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "\n",
    "# Contexto SSL customizado (caso precise ignorar erros SSL)\n",
    "ssl_context = ssl.create_default_context()\n",
    "ssl_context.check_hostname = False\n",
    "ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# Criar diretório base\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    \"\"\"Remove caracteres inválidos para nomes de arquivo\"\"\"\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", filename)\n",
    "\n",
    "def get_with_retry(url):\n",
    "    \"\"\"Faz uma requisição HTTP com retry e fallback para SSL desabilitado ou HTTP\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Tentativa {attempt + 1} para {url}\")\n",
    "            try:\n",
    "                response = session.get(url, timeout=timeout_seconds)\n",
    "                response.raise_for_status()\n",
    "                return response\n",
    "            except requests.exceptions.SSLError:\n",
    "                print(\"Falha SSL, tentando com verificação desativada...\")\n",
    "                response = session.get(url, timeout=timeout_seconds, verify=False)\n",
    "                response.raise_for_status()\n",
    "                return response\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Erro na tentativa {attempt + 1}: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)\n",
    "    if url.startswith('https://'):\n",
    "        http_url = url.replace('https://', 'http://', 1)\n",
    "        print(f\"Tentando fallback para HTTP: {http_url}\")\n",
    "        try:\n",
    "            response = session.get(http_url, timeout=timeout_seconds)\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Falha no fallback HTTP: {e}\")\n",
    "    return None\n",
    "\n",
    "def get_all_csv_links_from_ckan():\n",
    "    \"\"\"Consulta a API CKAN e retorna todos os arquivos CSV da organização\"\"\"\n",
    "    print(\"Consultando a API CKAN da CAPES...\")\n",
    "    params = {\n",
    "        \"fq\": f\"organization:{organization}\",\n",
    "        \"rows\": 1000\n",
    "    }\n",
    "    try:\n",
    "        response = session.get(api_url, params=params, timeout=timeout_seconds)\n",
    "        response.raise_for_status()\n",
    "        results = response.json()[\"result\"][\"results\"]\n",
    "        csv_links = []\n",
    "        for dataset in results:\n",
    "            for resource in dataset.get(\"resources\", []):\n",
    "                if resource.get(\"format\", \"\").lower() == \"csv\":\n",
    "                    url = resource.get(\"url\")\n",
    "                    if url:\n",
    "                        csv_links.append(url)\n",
    "        return sorted(set(csv_links))\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao consultar CKAN: {e}\")\n",
    "        return []\n",
    "\n",
    "def detect_subfolder(filename):\n",
    "    \"\"\"Detecta subpasta com base nas substrings do nome do arquivo\"\"\"\n",
    "    name = filename.lower()\n",
    "    for prefix, substrings in prefix_substring_dirs.items():\n",
    "        for substr, folder in substrings.items():\n",
    "            target = prefix + substr\n",
    "            if target in name:\n",
    "                return folder\n",
    "    return \"outros\"\n",
    "\n",
    "\n",
    "def download_csv_files(links):\n",
    "    \"\"\"Baixa todos os arquivos CSV e organiza em subpastas por tipo\"\"\"\n",
    "    total = len(links)\n",
    "    print(f\"\\nIniciando download de {total} arquivos...\")\n",
    "\n",
    "    for i, url in enumerate(links, 1):\n",
    "        try:\n",
    "            raw_filename = url.split('/')[-1].split('?')[0]\n",
    "            filename = sanitize_filename(raw_filename)\n",
    "            subfolder = detect_subfolder(filename)\n",
    "\n",
    "            subdir_path = os.path.join(output_dir, subfolder)\n",
    "            os.makedirs(subdir_path, exist_ok=True)\n",
    "\n",
    "            filepath = os.path.join(subdir_path, filename)\n",
    "\n",
    "            if os.path.exists(filepath):\n",
    "                print(f\"[{i}/{total}] Já existe: {subfolder}/{filename}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"[{i}/{total}] Baixando: {filename} para {subfolder}/\")\n",
    "\n",
    "            start_time = time.time()\n",
    "            response = get_with_retry(url)\n",
    "            if not response:\n",
    "                print(f\"Falha ao baixar {url}\")\n",
    "                continue\n",
    "\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "            print(f\"Salvo como {subfolder}/{filename} ({size_mb:.2f} MB) em {time.time() - start_time:.2f}s\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao baixar {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e0206-605c-4c5f-99e7-77526f15b886",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Código para download dos dados abertos - Processo potencialmente demorado\n",
    "print(\"Iniciando processo para baixar todos os CSVs da Diretoria de Avaliação...\")\n",
    "start_time = time.time()\n",
    "try:\n",
    "    csv_links = get_all_csv_links_from_ckan()\n",
    "    print(f\"\\n{len(csv_links)} arquivos CSV encontrados:\")\n",
    "    for i, link in enumerate(csv_links[:10], 1):\n",
    "        print(f\"{i}. {link.split('/')[-1].split('?')[0]}\")\n",
    "    if len(csv_links) > 10:\n",
    "        print(f\"... mais {len(csv_links) - 10} arquivos\")\n",
    "    if csv_links:\n",
    "        download_csv_files(csv_links)\n",
    "    print(f\"\\nConcluído em {time.time() - start_time:.2f}s\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nProcesso interrompido pelo usuário.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4095fc0-e00a-4413-bca1-000dbc51f1aa",
   "metadata": {},
   "source": [
    "## Filtrando apenas registros da UFRJ dos dados abertos CAPES - 2013 em diante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451d0398-9dd5-4e9d-81b2-25afaf20770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para selecionar documentos csv via expressões regulares e após um dado ano (e.g. 2013)\n",
    "#A identificação do ano através do nome de arquivo desta função está adaptada à padronização de nomes dos arquivos da CAPES\n",
    "#Valores de anos que iniciam quadriênios (2013, 2017, 2021) funcionarão normalmente. Outros anos poderão apresentar problemas\n",
    "def filtrar_csvs_por_diretorio_regex_e_ano(\n",
    "    caminho_do_diretorio,\n",
    "    padroes_regex=None,\n",
    "    ano_minimo=None, \n",
    "    busca_recursiva=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Lista arquivos CSV em um diretório e os filtra com base em:\n",
    "    1. Padrões de expressão regular (regex)\n",
    "    2. Um ano mínimo encontrado no nome do arquivo.\n",
    "\n",
    "    Args:\n",
    "        caminho_do_diretorio (str): O caminho para o diretório base onde os CSVs estão.\n",
    "        padroes_regex (list, optional): Uma lista de strings de expressões regulares.\n",
    "                                        Arquivos devem corresponder a *qualquer um* desses padrões.\n",
    "                                        Default é None (não aplica filtro regex).\n",
    "        ano_minimo (int, optional): O ano mínimo (4 dígitos) para filtrar.\n",
    "                                    Captura o primeiro grupo de 4 dígitos encontrado no nome do arquivo.\n",
    "                                    Default é None (não aplica filtro de ano).\n",
    "        busca_recursiva (bool, optional): Se True, a função buscará CSVs em subpastas também.\n",
    "                                          Default é False.\n",
    "\n",
    "    Returns:\n",
    "        list: Uma lista de caminhos completos para os arquivos CSV que atendem a todos os critérios.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se 'caminho_do_diretorio' não for encontrado ou se nenhum filtro for especificado.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(caminho_do_diretorio):\n",
    "        print(f\"Erro: O diretório '{caminho_do_diretorio}' não foi encontrado.\")\n",
    "        return []\n",
    "\n",
    "    if not padroes_regex and ano_minimo is None:\n",
    "        print(\"Aviso: Nenhum filtro (regex ou ano mínimo) foi especificado. Retornando todos os CSVs.\")\n",
    "\n",
    "    todos_csvs_encontrados = []\n",
    "\n",
    "    # 1. Obter todos os arquivos CSV do diretório (e subpastas, se recursivo)\n",
    "    if busca_recursiva:\n",
    "        for root, _, files in os.walk(caminho_do_diretorio):\n",
    "            for nome_arquivo in files:\n",
    "                if nome_arquivo.lower().endswith(\".csv\"):\n",
    "                    todos_csvs_encontrados.append(os.path.join(root, nome_arquivo))\n",
    "    else:\n",
    "        for nome_arquivo in os.listdir(caminho_do_diretorio):\n",
    "            caminho_completo = os.path.join(caminho_do_diretorio, nome_arquivo)\n",
    "            if os.path.isfile(caminho_completo) and nome_arquivo.lower().endswith(\".csv\"):\n",
    "                todos_csvs_encontrados.append(caminho_completo)\n",
    "\n",
    "    arquivos_filtrados_parcial = todos_csvs_encontrados\n",
    "\n",
    "    # 2. Aplicar filtro por padrões Regex (se fornecidos)\n",
    "    if padroes_regex:\n",
    "        final_regex_filter = []\n",
    "        regexes_compilados = [re.compile(p, re.IGNORECASE) for p in padroes_regex]\n",
    "\n",
    "        for caminho_completo in arquivos_filtrados_parcial:\n",
    "            nome_base = os.path.basename(caminho_completo)\n",
    "            for regex in regexes_compilados:\n",
    "                if regex.search(nome_base):\n",
    "                    final_regex_filter.append(caminho_completo)\n",
    "                    break\n",
    "        arquivos_filtrados_parcial = final_regex_filter\n",
    "\n",
    "    # 3. Aplicar filtro por ano mínimo (se fornecido)\n",
    "    if ano_minimo is not None:\n",
    "        final_year_filter = []\n",
    "        # Regex para qualquer sequência de 4 dígitos - adaptado à padronização CAPES\n",
    "        # O padrão (\\d{4}) captura o ano. Valores de anos que iniciam quadriênios (2013, 2017, 2021)\n",
    "        # funcionarão normalmente. Outros anos poderão apresentar problemas se o formato 'discentes-AAAA'\n",
    "        # não for o primeiro e único lugar onde o ano pode estar.\n",
    "        padrao_ano_capes = re.compile(r'(\\d{4})') \n",
    "\n",
    "        for caminho_completo in arquivos_filtrados_parcial:\n",
    "            nome_base = os.path.basename(caminho_completo)\n",
    "            match = padrao_ano_capes.search(nome_base)\n",
    "            \n",
    "            if match:\n",
    "                ano_str = match.group(1)\n",
    "                try:\n",
    "                    ano_int = int(ano_str)\n",
    "                    if ano_int >= ano_minimo:\n",
    "                        final_year_filter.append(caminho_completo)\n",
    "                except ValueError:\n",
    "                    print(f\"Aviso: Não foi possível converter '{ano_str}' em ano inteiro para '{nome_base}'. Ignorando.\")\n",
    "        arquivos_filtrados_parcial = final_year_filter\n",
    "\n",
    "    return arquivos_filtrados_parcial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a24ea90-3242-40be-9899-26c401cc0055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para obter caminhos utilizando o dicionário de diretórios definido no começo deste documento\n",
    "def obter_caminho_completo(basedir_key, subdir_key, dirs=dirs):\n",
    "    \"\"\"\n",
    "    Concatena os caminhos correspondentes a 'basedir_key' e 'subdir_key'\n",
    "    do dicionário 'dirs' para formar um caminho completo.\n",
    "\n",
    "    Args:\n",
    "        basedir_key (str): A chave do diretório base em 'dirs'.\n",
    "        subdir_key (str): A chave do subdiretório em 'dirs'.\n",
    "        dirs (dict): Dicionário com o nome dos diretórios. Default: dirs.\n",
    "\n",
    "    Returns:\n",
    "        str: O caminho completo concatenado.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se 'basedir_key' ou 'subdir_key' não forem chaves válidas em 'dirs'.\n",
    "    \"\"\"\n",
    "    chaves_disponiveis = list(dirs.keys())\n",
    "\n",
    "    if basedir_key not in dirs:\n",
    "        raise ValueError(\n",
    "            f\"Erro: Chave '{basedir_key}' não encontrada em 'dirs' para basedir. \"\n",
    "            f\"Chaves disponíveis: {chaves_disponiveis}\"\n",
    "        )\n",
    "\n",
    "    if subdir_key not in dirs:\n",
    "        raise ValueError(\n",
    "            f\"Erro: Chave '{subdir_key}' não encontrada em 'dirs' para subdir. \"\n",
    "            f\"Chaves disponíveis: {chaves_disponiveis}\"\n",
    "        )\n",
    "    \n",
    "    # Obtém os valores de diretório do dicionário\n",
    "    base_path = dirs[basedir_key]\n",
    "    sub_path = dirs[subdir_key]\n",
    "\n",
    "    # Concatena os caminhos usando os.path.join para compatibilidade entre sistemas\n",
    "    caminho_final = os.path.join(base_path, sub_path)\n",
    "    \n",
    "    return caminho_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2601943-e15c-4b7f-8e8b-5f9bb6b48510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Junção das funções 'filtrar_csvs_por_diretorio_regex_e_ano()' e 'obter_caminho_completo()'\n",
    "#Usada para obter uma lista com os arquivos csv de interesse a serem unificados em uma tabela única\n",
    "def selecionar_csvs_capes(\n",
    "    basedir_key,\n",
    "    subdir_key,\n",
    "    dirs=dirs,\n",
    "    padroes_regex=None,\n",
    "    ano_minimo=2013,\n",
    "    busca_recursiva=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Integra as funções para obter o caminho completo do diretório e filtrar arquivos CSV.\n",
    "\n",
    "    Args:\n",
    "        dirs (dict): Dicionário com o nome dos diretórios. Default: dirs.\n",
    "        basedir_key (str): A chave do diretório base em 'dirs' (e.g., 'download_dir', 'ufrj_dir').\n",
    "        subdir_key (str): A chave do subdiretório em 'dirs' (e.g., 'discentes', 'producao').\n",
    "        padroes_regex (list, optional): Uma lista de strings de expressões regulares para filtrar nomes de arquivo.\n",
    "                                        Arquivos devem corresponder a *qualquer um* desses padrões.\n",
    "                                        Default é None (não aplica filtro regex).\n",
    "        ano_minimo (int, optional): O ano mínimo (4 dígitos) para filtrar.\n",
    "                                    Adapta-se ao padrão \"discentes-AAAA\" dos arquivos da CAPES.\n",
    "                                    Valores de anos que iniciam quadriênios (2013, 2017, 2021) funcionarão\n",
    "                                    normalmente. Outros anos poderão apresentar problemas se o formato não se encaixar.\n",
    "                                    Default é None (não aplica filtro de ano).\n",
    "        busca_recursiva (bool, optional): Se True, a função buscará CSVs em subpastas do diretório gerado.\n",
    "                                          Default é False.\n",
    "\n",
    "    Returns:\n",
    "        list: Uma lista de caminhos completos para os arquivos CSV que atendem a todos os critérios.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se 'basedir_key' ou 'subdir_key' forem inválidas, ou se o diretório final não existir.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Obter o caminho completo do diretório usando as chaves\n",
    "        caminho_do_diretorio_completo = obter_caminho_completo(basedir_key, subdir_key)\n",
    "        print(f\"Buscando arquivos no diretório: {caminho_do_diretorio_completo}\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Erro ao obter caminho do diretório: {e}\")\n",
    "        return []\n",
    "\n",
    "    # 2. Filtrar os arquivos CSV dentro do diretório gerado\n",
    "    arquivos_selecionados = filtrar_csvs_por_diretorio_regex_e_ano(\n",
    "        caminho_do_diretorio=caminho_do_diretorio_completo,\n",
    "        padroes_regex=padroes_regex,\n",
    "        ano_minimo=ano_minimo,\n",
    "        busca_recursiva=busca_recursiva\n",
    "    )\n",
    "\n",
    "    return arquivos_selecionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef0c101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para processar e salvar csvs relacionados em um único arquivo\n",
    "def fundir_lista_csvs(\n",
    "        lista_caminhos_csv,\n",
    "        colunas_desejadas,\n",
    "        condicao_filtro_funcao,\n",
    "        diretorio_saida,\n",
    "        nome_arquivo_saida=\"saida_otimizada_lista.csv\",\n",
    "        chunk_size=10000,\n",
    "        colunas_para_int64=None\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Processa uma lista de arquivos CSV, extraindo colunas e linhas específicas de forma otimizada para RAM\n",
    "    usando leitura em chunks. Inclui opção para converter colunas para tipo Int64 (inteiro com nulos)\n",
    "    e lida com colunas ausentes em arquivos CSV.\n",
    "\n",
    "    Args:\n",
    "        lista_caminhos_csv (list): Uma lista de strings, onde cada string é o caminho completo para um arquivo CSV.\n",
    "        colunas_desejadas (list): Uma lista de nomes de colunas a serem extraídas.\n",
    "                                   A coluna usada para o filtro (se houver) deve ser incluída explicitamente aqui\n",
    "                                   se você quiser que ela apareça no resultado final.\n",
    "        condicao_filtro_funcao (function): Uma função que recebe uma linha (como Series do pandas)\n",
    "                                           e retorna True se a linha deve ser incluída, False caso contrário.\n",
    "        diretorio_saida (str): O caminho para o diretório onde o arquivo de saída será salvo.\n",
    "        nome_arquivo_saida (str): O nome do arquivo CSV de saída (ex: \"meu_arquivo.csv\").\n",
    "        chunk_size (int): O número de linhas a serem lidas por vez de cada arquivo CSV.\n",
    "        colunas_para_int64 (list, optional): Uma lista de nomes de colunas que devem ser convertidas\n",
    "                                              para o tipo 'Int64' (inteiro com suporte a nulos) antes de salvar.\n",
    "                                              Isso evita a adição de '.0' em IDs. Default é None.\n",
    "    \"\"\"\n",
    "    primeiro_arquivo = True\n",
    "    coluna_filtro = None # Manter para compatibilidade, mas não será mais usado para adicionar/remover colunas\n",
    "\n",
    "    caminho_completo_saida = os.path.join(diretorio_saida, nome_arquivo_saida)\n",
    "\n",
    "    if diretorio_saida and not os.path.exists(diretorio_saida):\n",
    "        os.makedirs(diretorio_saida, exist_ok=True)\n",
    "        print(f\"Diretório de saída criado: {diretorio_saida}\")\n",
    "\n",
    "    # A lógica de modificação de colunas_desejadas e colunas_para_salvar foi removida\n",
    "    colunas_para_ler = list(colunas_desejadas) # Agora 'colunas_para_ler' é simplesmente 'colunas_desejadas'\n",
    "    colunas_para_salvar = list(colunas_desejadas) # E 'colunas_para_salvar' também\n",
    "\n",
    "    # A lógica de remoção da coluna de filtro também foi removida\n",
    "    # if remove_filter_col e a lógica associada não estão mais presentes\n",
    "\n",
    "    for caminho_completo_arquivo_entrada in lista_caminhos_csv:\n",
    "        if not os.path.exists(caminho_completo_arquivo_entrada):\n",
    "            print(f\"Aviso: Arquivo não encontrado - {caminho_completo_arquivo_entrada}. Pulando...\")\n",
    "            continue\n",
    "        if not caminho_completo_arquivo_entrada.lower().endswith(\".csv\"):\n",
    "            print(f\"Aviso: Ignorando arquivo não CSV - {caminho_completo_arquivo_entrada}.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processando {caminho_completo_arquivo_entrada}...\")\n",
    "\n",
    "        # Ler o cabeçalho para verificar as colunas presentes\n",
    "        try:\n",
    "            df_header = pd.read_csv(caminho_completo_arquivo_entrada, sep=';', encoding='latin1', nrows=0)\n",
    "            colunas_presentes_no_arquivo = df_header.columns.tolist()\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler o cabeçalho do arquivo {caminho_completo_arquivo_entrada}: {e}. Pulando...\")\n",
    "            continue\n",
    "\n",
    "        # Identificar colunas a serem lidas que realmente existem no arquivo\n",
    "        colunas_a_realmente_ler = [col for col in colunas_para_ler if col in colunas_presentes_no_arquivo]\n",
    "        colunas_ausentes_neste_arquivo = [col for col in colunas_para_ler if col not in colunas_presentes_no_arquivo]\n",
    "\n",
    "        if colunas_ausentes_neste_arquivo:\n",
    "            print(f\"Aviso: As seguintes colunas desejadas não foram encontradas em '{caminho_completo_arquivo_entrada}': {', '.join(colunas_ausentes_neste_arquivo)}. Elas serão adicionadas como vazias.\")\n",
    "\n",
    "        read_csv_args = {\n",
    "            'sep': ';',\n",
    "            'encoding': 'latin1',\n",
    "            'usecols': colunas_a_realmente_ler,\n",
    "            'chunksize': chunk_size\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            for chunk in pd.read_csv(caminho_completo_arquivo_entrada, **read_csv_args):\n",
    "                # Adicionar colunas ausentes no chunk com valores NaN (vazios)\n",
    "                for col in colunas_ausentes_neste_arquivo:\n",
    "                    chunk[col] = pd.NA\n",
    "\n",
    "                df_filtrado = chunk[chunk.apply(condicao_filtro_funcao, axis=1)]\n",
    "\n",
    "                # Certificar-se de que todas as colunas desejadas estão presentes antes de selecionar\n",
    "                # e manter a ordem das colunas definidas em colunas_para_salvar\n",
    "                df_final = pd.DataFrame(columns=colunas_para_salvar)\n",
    "                for col in colunas_para_salvar:\n",
    "                    if col in df_filtrado.columns:\n",
    "                        df_final[col] = df_filtrado[col]\n",
    "                    else:\n",
    "                        df_final[col] = pd.NA\n",
    "\n",
    "                # NOVO PASSO: Converter as colunas especificadas para Int64Dtype\n",
    "                if colunas_para_int64:\n",
    "                    for col in colunas_para_int64:\n",
    "                        if col in df_final.columns:\n",
    "                            try:\n",
    "                                df_final[col] = pd.to_numeric(df_final[col], errors='coerce')\n",
    "                                df_final[col] = df_final[col].astype('Int64')\n",
    "                            except Exception as e:\n",
    "                                print(f\"Aviso: Não foi possível converter a coluna '{col}' para Int64 no chunk. Erro: {e}\")\n",
    "                        else:\n",
    "                            print(f\"Aviso: Coluna '{col}' não encontrada no DataFrame para conversão para Int64 neste chunk.\")\n",
    "\n",
    "                if primeiro_arquivo:\n",
    "                    df_final.to_csv(caminho_completo_saida, mode='w', index=False)\n",
    "                    primeiro_arquivo = False\n",
    "                else:\n",
    "                    df_final.to_csv(caminho_completo_saida, mode='a', header=False, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler ou processar o arquivo {caminho_completo_arquivo_entrada} em chunks: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Processamento concluído. Saída salva em {caminho_completo_saida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8740777-f100-477f-b030-89ac549f9e21",
   "metadata": {},
   "source": [
    "### Discentes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9d9ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição de filtro \n",
    "def filtro_ufrj_sigla(linha):\n",
    "    \"\"\"\n",
    "    Verifica se a linha atende aos critérios de filtro:\n",
    "    - 'SG_ENTIDADE_ENSINO' é 'UFRJ'.\n",
    "\n",
    "    Args:\n",
    "        linha (pd.Series): Uma linha do DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        bool: True se a linha atende aos critérios, False caso contrário.\n",
    "    \"\"\"\n",
    "    condicao_entidade = linha['SG_ENTIDADE_ENSINO'].strip().upper() == 'UFRJ'\n",
    "\n",
    "    return condicao_entidade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d58ccb11-214f-4710-a401-6e1b3cbd4287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando arquivos no diretório: capes_csv_files/discentes\n"
     ]
    }
   ],
   "source": [
    "#Obtendo lista de arquivos csv com ano de referencia = 2013 ou maior (sem filtragem por regex)\n",
    "discentes_csvs = selecionar_csvs_capes('download_dir', 'discentes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eccaa8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['capes_csv_files/discentes/br-capes-colsucup-discentes-2021-2025-03-31.csv',\n",
       " 'capes_csv_files/discentes/br-capes-colsucup-discentes-2013-2021-03-01.csv',\n",
       " 'capes_csv_files/discentes/br-capes-colsucup-discentes-2022-2025-03-31.csv',\n",
       " 'capes_csv_files/discentes/br-capes-colsucup-discentes-2014-2021-03-01.csv',\n",
       " 'capes_csv_files/discentes/br-capes-colsucup-discentes-2020-2023-12-01.csv',\n",
       " 'capes_csv_files/discentes/br-capes-colsucup-discentes-2016-2021-03-01.csv',\n",
       " 'capes_csv_files/discentes/br-capes-colsucup-discentes-2023-2025-03-31.csv',\n",
       " 'capes_csv_files/discentes/br-capes-colsucup-discentes-2018-2023-12-01.csv',\n",
       " 'capes_csv_files/discentes/br-capes-colsucup-discentes-2015-2021-03-01.csv',\n",
       " 'capes_csv_files/discentes/br-capes-colsucup-discentes-2019-2023-12-01.csv',\n",
       " 'capes_csv_files/discentes/br-capes-colsucup-discentes-2017-2023-12-01.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discentes_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f24cfdc-6ca4-46f8-9793-b03832e0fdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando capes_csv_files/discentes/br-capes-colsucup-discentes-2021-2025-03-31.csv...\n",
      "Processando capes_csv_files/discentes/br-capes-colsucup-discentes-2013-2021-03-01.csv...\n",
      "Processando capes_csv_files/discentes/br-capes-colsucup-discentes-2022-2025-03-31.csv...\n",
      "Processando capes_csv_files/discentes/br-capes-colsucup-discentes-2014-2021-03-01.csv...\n",
      "Processando capes_csv_files/discentes/br-capes-colsucup-discentes-2020-2023-12-01.csv...\n",
      "Processando capes_csv_files/discentes/br-capes-colsucup-discentes-2016-2021-03-01.csv...\n",
      "Processando capes_csv_files/discentes/br-capes-colsucup-discentes-2023-2025-03-31.csv...\n",
      "Processando capes_csv_files/discentes/br-capes-colsucup-discentes-2018-2023-12-01.csv...\n",
      "Processando capes_csv_files/discentes/br-capes-colsucup-discentes-2015-2021-03-01.csv...\n",
      "Processando capes_csv_files/discentes/br-capes-colsucup-discentes-2019-2023-12-01.csv...\n",
      "Processando capes_csv_files/discentes/br-capes-colsucup-discentes-2017-2023-12-01.csv...\n",
      "Processamento concluído. Saída salva em ufrj_data/discentes.csv\n"
     ]
    }
   ],
   "source": [
    "fundir_lista_csvs(discentes_csvs, \n",
    "                colunas_desejadas=['AN_BASE', 'ID_PESSOA', 'CD_PROGRAMA_IES', 'NM_DISCENTE', 'DS_TIPO_NACIONALIDADE_DISCENTE', \n",
    "                                    'NM_PAIS_NACIONALIDADE_DISCENTE', 'AN_NASCIMENTO_DISCENTE',\n",
    "                                    'DS_GRAU_ACADEMICO_DISCENTE', 'ST_INGRESSANTE', 'NM_SITUACAO_DISCENTE',\n",
    "                                    'QT_MES_TITULACAO', 'SG_ENTIDADE_ENSINO'], \n",
    "                                    condicao_filtro_funcao=filtro_ufrj_sigla,\n",
    "                                    diretorio_saida=filtered_dir,\n",
    "                                    nome_arquivo_saida='discentes.csv'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639a9c6",
   "metadata": {},
   "source": [
    "### Docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "151b2ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando arquivos no diretório: capes_csv_files/docentes\n"
     ]
    }
   ],
   "source": [
    "docentes_csvs = selecionar_csvs_capes('download_dir', 'docentes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa8a7b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['capes_csv_files/docentes/br-capes-colsucup-docente-2023-2025-03-31.csv',\n",
       " 'capes_csv_files/docentes/br-capes-colsucup-docente-2013-2023-08-01.csv',\n",
       " 'capes_csv_files/docentes/br-capes-colsucup-docente-2019-2021-11-10.csv',\n",
       " 'capes_csv_files/docentes/br-capes-colsucup-docente-2022-2025-03-31.csv',\n",
       " 'capes_csv_files/docentes/br-capes-colsucup-docente-2015-2023-08-01.csv',\n",
       " 'capes_csv_files/docentes/br-capes-colsucup-docente-2020-2021-11-10.csv',\n",
       " 'capes_csv_files/docentes/br-capes-colsucup-docente-2017-2021-11-10.csv',\n",
       " 'capes_csv_files/docentes/br-capes-colsucup-docente-2021-2025-03-31.csv',\n",
       " 'capes_csv_files/docentes/br-capes-colsucup-docente-2016-2023-08-01.csv',\n",
       " 'capes_csv_files/docentes/br-capes-colsucup-docente-2014-2023-08-01.csv',\n",
       " 'capes_csv_files/docentes/br-capes-colsucup-docente-2018-2021-11-10.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docentes_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3282016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro_docente(linha):\n",
    "    \"\"\"\n",
    "    Verifica se a linha atende aos critérios de filtro:\n",
    "    - 'SG_ENTIDADE_ENSINO' é 'UFRJ'.\n",
    "    - 'DS_CATEGORIA_DOCENTE' é 'PERMANENTE'\n",
    "\n",
    "    Args:\n",
    "        linha (pd.Series): Uma linha do DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        bool: True se a linha atende aos critérios, False caso contrário.\n",
    "    \"\"\"\n",
    "    condicao_entidade = linha['SG_ENTIDADE_ENSINO'].strip().upper() == 'UFRJ'\n",
    "    condicao_categoria_docente = linha['DS_CATEGORIA_DOCENTE'].strip().upper() == 'PERMANENTE'\n",
    "\n",
    "    return condicao_entidade and condicao_categoria_docente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91f56dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando capes_csv_files/docentes/br-capes-colsucup-docente-2023-2025-03-31.csv...\n",
      "Processando capes_csv_files/docentes/br-capes-colsucup-docente-2013-2023-08-01.csv...\n",
      "Processando capes_csv_files/docentes/br-capes-colsucup-docente-2019-2021-11-10.csv...\n",
      "Processando capes_csv_files/docentes/br-capes-colsucup-docente-2022-2025-03-31.csv...\n",
      "Processando capes_csv_files/docentes/br-capes-colsucup-docente-2015-2023-08-01.csv...\n",
      "Processando capes_csv_files/docentes/br-capes-colsucup-docente-2020-2021-11-10.csv...\n",
      "Processando capes_csv_files/docentes/br-capes-colsucup-docente-2017-2021-11-10.csv...\n",
      "Processando capes_csv_files/docentes/br-capes-colsucup-docente-2021-2025-03-31.csv...\n",
      "Processando capes_csv_files/docentes/br-capes-colsucup-docente-2016-2023-08-01.csv...\n",
      "Processando capes_csv_files/docentes/br-capes-colsucup-docente-2014-2023-08-01.csv...\n",
      "Processando capes_csv_files/docentes/br-capes-colsucup-docente-2018-2021-11-10.csv...\n",
      "Processamento concluído. Saída salva em ufrj_data/docentes.csv\n"
     ]
    }
   ],
   "source": [
    "fundir_lista_csvs(docentes_csvs, \n",
    "                  colunas_desejadas=['AN_BASE', 'ID_PESSOA', 'CD_PROGRAMA_IES',\n",
    "                  'NM_DOCENTE', 'AN_NASCIMENTO_DOCENTE', 'DS_TIPO_NACIONALIDADE_DOCENTE',\n",
    "                  'NM_PAIS_NACIONALIDADE_DOCENTE', 'DS_CATEGORIA_DOCENTE', \n",
    "                  'DS_TIPO_VINCULO_DOCENTE_IES', 'DS_REGIME_TRABALHO',\n",
    "                  'CD_CAT_BOLSA_PRODUTIVIDADE', 'NM_GRAU_TITULACAO', 'SG_ENTIDADE_ENSINO'], \n",
    "                  condicao_filtro_funcao=filtro_docente,\n",
    "                  diretorio_saida=filtered_dir,\n",
    "                  nome_arquivo_saida='docentes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f921b1d",
   "metadata": {},
   "source": [
    "### Programas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc054ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "programas_csvs = selecionar_csvs_capes('download_dir', 'programas', padroes_regex=[r\"br-capes-colsucup-prog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "programas_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72310d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fundir_lista_csvs(programas_csvs, ['AN_BASE', 'CD_PROGRAMA_IES', 'NM_PROGRAMA_IES', 'NM_GRANDE_AREA_CONHECIMENTO', \n",
    "                                    'NM_GRAU_PROGRAMA', 'CD_CONCEITO_PROGRAMA', 'ANO_INICIO_PROGRAMA', 'AN_INICIO_PROGRAMA',\n",
    "                                    'AN_INICIO_CURSO', 'IN_REDE', 'DS_SITUACAO_PROGRAMA',\n",
    "                                    'CD_AREA_AVALIACAO', 'NM_AREA_AVALIACAO', 'NM_MODALIDADE_PROGRAMA', 'SG_ENTIDADE_ENSINO',\n",
    "                                   ], \n",
    "                                   condicao_filtro_funcao=filtro_ufrj_sigla,\n",
    "                                   diretorio_saida=filtered_dir,\n",
    "                                   nome_arquivo_saida='programas.csv'\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1493e17f",
   "metadata": {},
   "source": [
    "### Produção (artigos de periódicos por autor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3253f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "producao_csvs = selecionar_csvs_capes('download_dir', 'producao', padroes_regex=[r\"br-capes-colsucup-prod-autor-.*bibliografica-artpe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320e891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "producao_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22348295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro_producao(linha):\n",
    "    \"\"\"\n",
    "    Verifica se a linha atende aos critérios de filtro:\n",
    "    - 'SG_ENTIDADE_ENSINO' é 'UFRJ'.\n",
    "    - 'ID_PESSOA_DOCENTE' não é nulo.\n",
    "    - 'ID_PESSOA_DISCENTE' não é nulo.\n",
    "    - 'NM_TP_CATEGORIA_DOCENTE' é 'PERMANENTE'.\n",
    "    - 'NM_NIVEL_DISCENTE' está em algum nível que corresponda a alunos de pós.\n",
    "\n",
    "    Args:\n",
    "        linha (pd.Series): Uma linha do DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        bool: True se a linha atende aos critérios, False caso contrário.\n",
    "    \"\"\"\n",
    "    condicao_entidade = linha['SG_ENTIDADE_ENSINO'].strip().upper() == 'UFRJ'\n",
    "    condicao_discente_nao_nulo = pd.notna(linha['ID_PESSOA_DISCENTE'])\n",
    "    condicao_docente_nao_nulo = pd.notna(linha['ID_PESSOA_DOCENTE'])\n",
    "\n",
    "    condicao_categoria_docente = True #Se a linha não estiver se referindo a docente, isso deve ser verdadeiro para não excluir o registro\n",
    "    condicao_nivel_discente = True #Se a linha não estiver se referindo a discente, isso deve ser verdadeiro para não excluir o registro\n",
    "\n",
    "    if condicao_docente_nao_nulo:\n",
    "        nm_categoria_docente = str(linha.get('NM_TP_CATEGORIA_DOCENTE', '')).strip().upper()\n",
    "        condicao_categoria_docente = (nm_categoria_docente == 'PERMANENTE') #Só inclui docentes permanentes\n",
    "    elif condicao_discente_nao_nulo:\n",
    "        nm_nivel_discente = str(linha.get('NM_NIVEL_DISCENTE', '')).strip().upper()\n",
    "        condicao_nivel_discente = (nm_nivel_discente in ['MESTRADO', 'DOUTORADO', 'MESTRADO PROFISSIONAL', 'DOUTORADO PROFISSIONAL']) #Só inclui alunos de pós \n",
    "    \n",
    "    return condicao_entidade and (condicao_discente_nao_nulo or condicao_docente_nao_nulo) and condicao_categoria_docente and condicao_nivel_discente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d012c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fundir_lista_csvs(producao_csvs, \n",
    "                colunas_desejadas=['AN_BASE', 'CD_PROGRAMA_IES', 'ID_ADD_PRODUCAO_INTELECTUAL', \n",
    "                                   'ID_PESSOA_DOCENTE', 'ID_PESSOA_DISCENTE', 'TP_AUTOR', \n",
    "                                   'NM_TP_CATEGORIA_DOCENTE', 'NM_NIVEL_DISCENTE', 'SG_ENTIDADE_ENSINO'], \n",
    "                condicao_filtro_funcao=filtro_producao, \n",
    "                diretorio_saida=filtered_dir,\n",
    "                nome_arquivo_saida='producao.csv',\n",
    "                colunas_para_int64= ['ID_PESSOA_DOCENTE', 'ID_PESSOA_DISCENTE'] ,\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f358c",
   "metadata": {},
   "source": [
    "## Processamento/limpeza dos dados da ufrj\n",
    "\n",
    "- Discentes:\n",
    "    - Geração da coluna de gênero/remoção da coluna de nome\n",
    "    - Converter ST_INGRESSANTE para booleano\n",
    "\n",
    "- Docentes: \n",
    "    - Geração da coluna de gênero/remoção da coluna de nome\n",
    "    - Limpeza campo CD_CAT_BOLSA_PRODUTIVIDADE (remover os NA e SR)\n",
    "\n",
    "- Pessoas:\n",
    "    - Pegar os campos de docentes e discentes que não mudam ao longo dos anos\n",
    "\n",
    "- Programas:\n",
    "    - Campo IN_REDE convertido para booleano\n",
    "    - Substituir conceito 'A' ('Ausente') por 0\n",
    "    - Fundir colunas ANO_INICIO_PROGRAMA (2013-2016) e AN_INICIO_PROGRAMA (2017 em diante)\n",
    "    - Gerar a tabela 'programa' (informações que não mudam ao longo dos anos)\n",
    "    - Gerar a tabela 'ano_programa', contendo apenas as informações sobre os programas que podem mudar ao longo dos anos\n",
    "    - Gerar a tabela 'cursos', com a relação entre CD_PROGRAMA_IES, NM_GRAU_PROGRAMA e ANO_INICIO_CURSO\n",
    "        - Separar os valores separados por barra em NM_GRAU_PROGRAMA (e.g. MESTRADO/DOUTORADO) e ANO_INICIO_CURSO (e.g. 1981/2001)\n",
    "        - Adicionar outras linhas normalmente\n",
    "\n",
    "- Produção:\n",
    "    - Unir as colunas ID_PESSOA_DOCENTE e ID_PESSOA_DISCENTE em uma só\n",
    "\n",
    "- Todas:\n",
    "    - Remover as colunas usadas para a filtragem dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2caa021f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AALINE': 'F',\n",
       " 'AILINE': 'F',\n",
       " 'ALEINE': 'F',\n",
       " 'ALIINE': 'F',\n",
       " 'ALINE': 'F',\n",
       " 'ALINER': 'F',\n",
       " 'ALINHE': 'F',\n",
       " 'ALINNE': 'F',\n",
       " 'ALYNE': 'F',\n",
       " 'ALYNNE': 'F',\n",
       " 'AYLINE': 'F',\n",
       " 'EALINE': 'F',\n",
       " 'ELEINE': 'F',\n",
       " 'ELINE': 'F',\n",
       " 'ELINER': 'F',\n",
       " 'ELINNE': 'F',\n",
       " 'ELYNE': 'F',\n",
       " 'EULINE': 'F',\n",
       " 'HALINE': 'F',\n",
       " 'HALYNE': 'F',\n",
       " 'HELEINE': 'F',\n",
       " 'HELINE': 'F',\n",
       " 'HELYNE': 'F',\n",
       " 'IALINE': 'F',\n",
       " 'ILEINE': 'F',\n",
       " 'ILINE': 'F',\n",
       " 'LEINE': 'F',\n",
       " 'LEINER': 'F',\n",
       " 'LEYNE': 'F',\n",
       " 'LINE': 'F',\n",
       " 'LINER': 'F',\n",
       " 'LUEINE': 'F',\n",
       " 'LUINE': 'F',\n",
       " 'LUYNE': 'F',\n",
       " 'LYNE': 'F',\n",
       " 'LYNNE': 'F',\n",
       " 'OLINE': 'F',\n",
       " 'UELINE': 'F',\n",
       " 'AARAO': 'M',\n",
       " 'ARAAO': 'M',\n",
       " 'ARAO': 'M',\n",
       " 'AARON': 'M',\n",
       " 'AHARON': 'M',\n",
       " 'AROM': 'M',\n",
       " 'ARON': 'M',\n",
       " 'ARYON': 'M',\n",
       " 'HARON': 'M',\n",
       " 'ABA': 'F',\n",
       " 'ADA': 'F',\n",
       " 'ADAH': 'F',\n",
       " 'ADAR': 'F',\n",
       " 'ADHA': 'F',\n",
       " 'HADA': 'F',\n",
       " 'ABADE': 'M',\n",
       " 'ABADI': 'M',\n",
       " 'ABADIR': 'M',\n",
       " 'ABADIA': 'F',\n",
       " 'ABADIAS': 'M',\n",
       " 'ABADIO': 'M',\n",
       " 'ABAETE': 'F',\n",
       " 'ABETE': 'F',\n",
       " 'ADETE': 'F',\n",
       " 'ABD': 'M',\n",
       " 'ABDA': 'F',\n",
       " 'ADDA': 'F',\n",
       " 'ABDAEL': 'M',\n",
       " 'ABDAL': 'M',\n",
       " 'ABDEEL': 'M',\n",
       " 'ABDEL': 'M',\n",
       " 'ABDIEL': 'M',\n",
       " 'ABDUL': 'M',\n",
       " 'ADBEEL': 'M',\n",
       " 'ADBEL': 'M',\n",
       " 'ADBIEL': 'M',\n",
       " 'ABDALA': 'M',\n",
       " 'ABDALLA': 'M',\n",
       " 'ABDALLAH': 'M',\n",
       " 'ABDAO': 'M',\n",
       " 'ABDE': 'M',\n",
       " 'ABDER': 'M',\n",
       " 'ADBE': 'M',\n",
       " 'ABDENAGO': 'M',\n",
       " 'ABDENEGO': 'M',\n",
       " 'ABDENICO': 'M',\n",
       " 'ABDENIGO': 'M',\n",
       " 'ABDENIO': 'M',\n",
       " 'ABDENOR': 'M',\n",
       " 'ABDERMAN': 'M',\n",
       " 'ABDI': 'M',\n",
       " 'ABDIR': 'M',\n",
       " 'ADBI': 'M',\n",
       " 'ADDY': 'M',\n",
       " 'ABDIA': 'M',\n",
       " 'ABDIAS': 'M',\n",
       " 'ABDISIO': 'M',\n",
       " 'ABDNEGO': 'M',\n",
       " 'ABDO': 'M',\n",
       " 'ABDOM': 'M',\n",
       " 'ABDON': 'M',\n",
       " 'ABDORAL': 'M',\n",
       " 'ABDU': 'M',\n",
       " 'ABE': 'M',\n",
       " 'ABER': 'M',\n",
       " 'ADE': 'M',\n",
       " 'ADER': 'M',\n",
       " 'HADER': 'M',\n",
       " 'ABECIO': 'M',\n",
       " 'ADECIO': 'M',\n",
       " 'ABEDENEGO': 'M',\n",
       " 'ABEDIAS': 'M',\n",
       " 'ADEDIAS': 'M',\n",
       " 'ABEDIEL': 'M',\n",
       " 'ADEBAL': 'M',\n",
       " 'ABEDNEGO': 'M',\n",
       " 'ABEDON': 'M',\n",
       " 'ABEGAIL': 'F',\n",
       " 'ADEGIL': 'F',\n",
       " 'ABEGAIR': 'M',\n",
       " 'ADEGAIR': 'M',\n",
       " 'ADEJAIR': 'M',\n",
       " 'ABEILARD': 'M',\n",
       " 'ABELARD': 'M',\n",
       " 'ABEILDO': 'M',\n",
       " 'ADAILDO': 'M',\n",
       " 'ADALDO': 'M',\n",
       " 'ADEALDO': 'M',\n",
       " 'ADEILDO': 'M',\n",
       " 'ADELDO': 'M',\n",
       " 'ADILDO': 'M',\n",
       " 'ADOALDO': 'M',\n",
       " 'ADUALDO': 'M',\n",
       " 'ABEILTON': 'M',\n",
       " 'ADAELTON': 'M',\n",
       " 'ADAILTOM': 'M',\n",
       " 'ADAILTON': 'M',\n",
       " 'ADALTOM': 'M',\n",
       " 'ADALTON': 'M',\n",
       " 'ADAYLTON': 'M',\n",
       " 'ADEILTOM': 'M',\n",
       " 'ADEILTON': 'M',\n",
       " 'ADELTOM': 'M',\n",
       " 'ADELTON': 'M',\n",
       " 'ADIELTON': 'M',\n",
       " 'ADILTOM': 'M',\n",
       " 'ADILTON': 'M',\n",
       " 'ADOILTON': 'M',\n",
       " 'HADAILTON': 'M',\n",
       " 'ABEL': 'M',\n",
       " 'ABIAIL': 'M',\n",
       " 'ABIEL': 'M',\n",
       " 'ABIL': 'M',\n",
       " 'ADAEL': 'M',\n",
       " 'ADAHIL': 'M',\n",
       " 'ADAHYL': 'M',\n",
       " 'ADAIL': 'M',\n",
       " 'ADAL': 'M',\n",
       " 'ADAYL': 'M',\n",
       " 'ADEIL': 'M',\n",
       " 'ADEL': 'M',\n",
       " 'ADIEL': 'M',\n",
       " 'ADIL': 'M',\n",
       " 'ADOEL': 'M',\n",
       " 'ADUIL': 'M',\n",
       " 'ADYEL': 'M',\n",
       " 'ADYL': 'M',\n",
       " 'ABELA': 'M',\n",
       " 'ABELAR': 'M',\n",
       " 'ABILA': 'M',\n",
       " 'ABILHA': 'M',\n",
       " 'ABLA': 'M',\n",
       " 'ADAILA': 'M',\n",
       " 'ADALA': 'M',\n",
       " 'ADALHA': 'M',\n",
       " 'ADEILA': 'M',\n",
       " 'ADELA': 'M',\n",
       " 'ADELAR': 'M',\n",
       " 'ADELHA': 'M',\n",
       " 'ADILA': 'M',\n",
       " 'ADILAR': 'M',\n",
       " 'ADILHA': 'M',\n",
       " 'ADLA': 'M',\n",
       " 'ADLAR': 'M',\n",
       " 'ADOLAR': 'M',\n",
       " 'ADYLA': 'M',\n",
       " 'HADILA': 'M',\n",
       " 'HADLA': 'M',\n",
       " 'ABELAIR': 'F',\n",
       " 'ABELIA': 'F',\n",
       " 'ABILIA': 'F',\n",
       " 'ADALHIA': 'F',\n",
       " 'ADALIA': 'F',\n",
       " 'ADELAI': 'F',\n",
       " 'ADELAIR': 'F',\n",
       " 'ADELHIA': 'F',\n",
       " 'ADELIA': 'F',\n",
       " 'ADILAI': 'F',\n",
       " 'ADILAIR': 'F',\n",
       " 'ADILIA': 'F',\n",
       " 'ADLAI': 'F',\n",
       " 'ADLAIR': 'F',\n",
       " 'ADLIA': 'F',\n",
       " 'ABELARDA': 'F',\n",
       " 'ABELARDO': 'M',\n",
       " 'ADALARDO': 'M',\n",
       " 'ADELARDO': 'M',\n",
       " 'ABELI': 'F',\n",
       " 'ABILI': 'F',\n",
       " 'ADAELI': 'F',\n",
       " 'ADALI': 'F',\n",
       " 'ADALIR': 'F',\n",
       " 'ADALY': 'F',\n",
       " 'ADELEI': 'F',\n",
       " 'ADELI': 'F',\n",
       " 'ADELIR': 'F',\n",
       " 'ADELY': 'F',\n",
       " 'ADIELI': 'F',\n",
       " 'ADIELY': 'F',\n",
       " 'ADILEI': 'F',\n",
       " 'ADILEY': 'F',\n",
       " 'ADILI': 'F',\n",
       " 'ADLEI': 'F',\n",
       " 'ADLEY': 'F',\n",
       " 'ADLI': 'F',\n",
       " 'ADLY': 'F',\n",
       " 'ADOLI': 'F',\n",
       " 'ADOLIR': 'F',\n",
       " 'HADLEY': 'F',\n",
       " 'ABELICE': 'F',\n",
       " 'ADALICE': 'F',\n",
       " 'ADELICE': 'F',\n",
       " 'ABELICIA': 'F',\n",
       " 'ADALICIA': 'F',\n",
       " 'ADELICIA': 'F',\n",
       " 'ABELINA': 'F',\n",
       " 'ADALINA': 'F',\n",
       " 'ADELINA': 'F',\n",
       " 'ADILINA': 'F',\n",
       " 'ADLINA': 'F',\n",
       " 'ADOLINA': 'F',\n",
       " 'ABELINE': 'F',\n",
       " 'ADALINE': 'F',\n",
       " 'ADELINE': 'F',\n",
       " 'ADILINE': 'F',\n",
       " 'ADLINE': 'F',\n",
       " 'ABELINO': 'M',\n",
       " 'ABILINO': 'M',\n",
       " 'ADALINO': 'M',\n",
       " 'ADELINO': 'M',\n",
       " 'ADILINO': 'M',\n",
       " 'ADLINO': 'M',\n",
       " 'ADOLINO': 'M',\n",
       " 'ABELIO': 'M',\n",
       " 'ABILHIO': 'M',\n",
       " 'ABILIO': 'M',\n",
       " 'ABLIO': 'M',\n",
       " 'ADAELIO': 'M',\n",
       " 'ADAILIO': 'M',\n",
       " 'ADALIO': 'M',\n",
       " 'ADELIO': 'M',\n",
       " 'ADILHIO': 'M',\n",
       " 'ADILIO': 'M',\n",
       " 'ADLIO': 'M',\n",
       " 'ADUILIO': 'M',\n",
       " 'ABELIRIO': 'M',\n",
       " 'ADALIRIO': 'M',\n",
       " 'ADELIRIO': 'M',\n",
       " 'ABELITA': 'F',\n",
       " 'ADALITA': 'F',\n",
       " 'ADELITA': 'F',\n",
       " 'ABELMAR': 'F',\n",
       " 'ABILMAR': 'F',\n",
       " 'ADAELMA': 'F',\n",
       " 'ADAILMA': 'F',\n",
       " 'ADALMA': 'F',\n",
       " 'ADALMAR': 'F',\n",
       " 'ADEILMA': 'F',\n",
       " 'ADELMA': 'F',\n",
       " 'ADELMAR': 'F',\n",
       " 'ADIELMA': 'F',\n",
       " 'ADILMA': 'F',\n",
       " 'ADILMAR': 'F',\n",
       " 'ABELO': 'M',\n",
       " 'ABELOR': 'M',\n",
       " 'ABILHO': 'M',\n",
       " 'ABILO': 'M',\n",
       " 'ABLO': 'M',\n",
       " 'ADAILO': 'M',\n",
       " 'ADALHO': 'M',\n",
       " 'ADALO': 'M',\n",
       " 'ADELHO': 'M',\n",
       " 'ADELO': 'M',\n",
       " 'ADELOR': 'M',\n",
       " 'ADILHO': 'M',\n",
       " 'ADILO': 'M',\n",
       " 'ADILOR': 'M',\n",
       " 'ADUILO': 'M',\n",
       " 'ABEILSON': 'M',\n",
       " 'ABELSON': 'M',\n",
       " 'ADAELSOM': 'M',\n",
       " 'ADAELSON': 'M',\n",
       " 'ADAILSOM': 'M',\n",
       " 'ADAILSON': 'M',\n",
       " 'ADAILZON': 'M',\n",
       " 'ADALSON': 'M',\n",
       " 'ADEILSOM': 'M',\n",
       " 'ADEILSON': 'M',\n",
       " 'ADELSOM': 'M',\n",
       " 'ADELSON': 'M',\n",
       " 'ADELZON': 'M',\n",
       " 'ADEYLSON': 'M',\n",
       " 'ADIELSOM': 'M',\n",
       " 'ADIELSON': 'M',\n",
       " 'ADIILSON': 'M',\n",
       " 'ADILSOM': 'M',\n",
       " 'ADILSON': 'M',\n",
       " 'ADLSOM': 'M',\n",
       " 'ADLSON': 'M',\n",
       " 'ADOILSOM': 'M',\n",
       " 'ADOILSON': 'M',\n",
       " 'ADOLSON': 'M',\n",
       " 'ADUILSON': 'M',\n",
       " 'ADYLSON': 'M',\n",
       " 'HADILSON': 'M',\n",
       " 'ABEMAEL': 'M',\n",
       " 'ADEMAEL': 'M',\n",
       " 'ADEMIL': 'M',\n",
       " 'ABEMOR': 'M',\n",
       " 'ADEMO': 'M',\n",
       " 'ADEMOR': 'M',\n",
       " 'ABENAIAS': 'M',\n",
       " 'ABENAIDE': 'F',\n",
       " 'ADENAIDE': 'F',\n",
       " 'ABENAIR': 'F',\n",
       " 'ADENAI': 'F',\n",
       " 'ADENAIR': 'F',\n",
       " 'ADENIA': 'F',\n",
       " 'ABENALDO': 'M',\n",
       " 'ABENILDO': 'M',\n",
       " 'ADENAILDO': 'M',\n",
       " 'ADENALDO': 'M',\n",
       " 'ADENILDO': 'M',\n",
       " 'ADENOALDO': 'M',\n",
       " 'ABENE': 'M',\n",
       " 'ABENER': 'M',\n",
       " 'ADAENE': 'M',\n",
       " 'ADENE': 'M',\n",
       " 'ADENER': 'M',\n",
       " 'ABENEIR': 'M',\n",
       " 'ABENI': 'M',\n",
       " 'ABENIR': 'M',\n",
       " 'ADENEI': 'M',\n",
       " 'ADENEIR': 'M',\n",
       " 'ADENI': 'M',\n",
       " 'ADENIR': 'M',\n",
       " 'ADENY': 'M',\n",
       " 'ADENYR': 'M',\n",
       " 'ABENEL': 'M',\n",
       " 'ABENIL': 'M',\n",
       " 'ADENAEL': 'M',\n",
       " 'ADENAIL': 'M',\n",
       " 'ADENAL': 'M',\n",
       " 'ADENIEL': 'M',\n",
       " 'ADENIL': 'M',\n",
       " 'ADENOEL': 'M',\n",
       " 'ABENEVALDO': 'M',\n",
       " 'ADENEVALDO': 'M',\n",
       " 'ABENIAS': 'M',\n",
       " 'ADENIAS': 'M',\n",
       " 'ABENICIO': 'M',\n",
       " 'ADENICIO': 'M',\n",
       " 'ABENAILDE': 'F',\n",
       " 'ABENILDE': 'F',\n",
       " 'ADENAILDE': 'F',\n",
       " 'ADENILDE': 'F',\n",
       " 'ABENILDES': 'F',\n",
       " 'ADENAILDES': 'F',\n",
       " 'ADENILDES': 'F',\n",
       " 'ABENILSON': 'M',\n",
       " 'ADENAILSON': 'M',\n",
       " 'ADENEILSON': 'M',\n",
       " 'ADENELSON': 'M',\n",
       " 'ADENIELSON': 'M',\n",
       " 'ADENILSOM': 'M',\n",
       " 'ADENILSON': 'M',\n",
       " 'ADENLSON': 'M',\n",
       " 'ABENAILTON': 'M',\n",
       " 'ABENILTON': 'M',\n",
       " 'ADENAILTON': 'M',\n",
       " 'ADENILTOM': 'M',\n",
       " 'ADENILTON': 'M',\n",
       " 'ADENLTON': 'M',\n",
       " 'ABENILZA': 'F',\n",
       " 'ADENILSA': 'F',\n",
       " 'ADENILZA': 'F',\n",
       " 'ABENITA': 'F',\n",
       " 'ADENITA': 'F',\n",
       " 'ABENIZA': 'F',\n",
       " 'ADENISA': 'F',\n",
       " 'ADENIZA': 'F',\n",
       " 'ABENIZIA': 'F',\n",
       " 'ADENISIA': 'F',\n",
       " 'ADENIZIA': 'F',\n",
       " 'ABENONE': 'M',\n",
       " 'ABENOR': 'M',\n",
       " 'ADENO': 'M',\n",
       " 'ADENOR': 'M',\n",
       " 'ABERALDO': 'M',\n",
       " 'ABEROALDO': 'M',\n",
       " 'ADERALDO': 'M',\n",
       " 'ADERILDO': 'M',\n",
       " 'ADEROALDO': 'M',\n",
       " 'ABERCIO': 'M',\n",
       " 'ADAERCIO': 'M',\n",
       " 'ADERCIO': 'M',\n",
       " 'ABERLADO': 'M',\n",
       " 'ABERLAN': 'M',\n",
       " 'ADERLAM': 'M',\n",
       " 'ADERLAN': 'M',\n",
       " 'ABERLANDIA': 'F',\n",
       " 'ADERLANDIA': 'F',\n",
       " 'ABERLARDO': 'M',\n",
       " 'ABERLINDO': 'M',\n",
       " 'ADERLINDO': 'M',\n",
       " 'ABERSON': 'M',\n",
       " 'ADERSOM': 'M',\n",
       " 'ADERSON': 'M',\n",
       " 'HADERSON': 'M',\n",
       " 'ABERVAL': 'M',\n",
       " 'ADERVAL': 'M',\n",
       " 'ABES': 'M',\n",
       " 'ADES': 'M',\n",
       " 'HADES': 'M',\n",
       " 'ABETINO': 'M',\n",
       " 'ADETINO': 'M',\n",
       " 'ABEVALDO': 'M',\n",
       " 'ADEVALDO': 'M',\n",
       " 'ABGAIL': 'F',\n",
       " 'ADJAEL': 'F',\n",
       " 'ABGAIR': 'M',\n",
       " 'ADGAIR': 'M',\n",
       " 'ADJAIR': 'M',\n",
       " 'ABHNER': 'M',\n",
       " 'ABNE': 'M',\n",
       " 'ABNER': 'M',\n",
       " 'ABNNER': 'M',\n",
       " 'ADNE': 'M',\n",
       " 'ADNER': 'M',\n",
       " 'HABNER': 'M',\n",
       " 'ABEIR': 'M',\n",
       " 'ABI': 'M',\n",
       " 'ABIR': 'M',\n",
       " 'ADEI': 'M',\n",
       " 'ADEIR': 'M',\n",
       " 'ADEY': 'M',\n",
       " 'ADI': 'M',\n",
       " 'ADIR': 'M',\n",
       " 'ADUIR': 'M',\n",
       " 'ADY': 'M',\n",
       " 'ADYR': 'M',\n",
       " 'HADI': 'M',\n",
       " 'HADY': 'M',\n",
       " 'ABIA': 'M',\n",
       " 'ADAHIR': 'M',\n",
       " 'ADAHYR': 'M',\n",
       " 'ADAI': 'M',\n",
       " 'ADAIR': 'M',\n",
       " 'ADAY': 'M',\n",
       " 'ADAYR': 'M',\n",
       " 'ADIA': 'M',\n",
       " 'HABIA': 'M',\n",
       " 'ABIAN': 'M',\n",
       " 'ADIAN': 'M',\n",
       " 'ABIANA': 'F',\n",
       " 'ADAINA': 'F',\n",
       " 'ADIANA': 'F',\n",
       " 'ABIANE': 'F',\n",
       " 'ADAINE': 'F',\n",
       " 'ADIANE': 'F',\n",
       " 'ABIAS': 'M',\n",
       " 'ADAIS': 'M',\n",
       " 'ADIAS': 'M',\n",
       " 'ABIATA': 'M',\n",
       " 'ABIATAR': 'M',\n",
       " 'ABIB': 'M',\n",
       " 'ADIB': 'M',\n",
       " 'HABIB': 'M',\n",
       " 'ABIDA': 'F',\n",
       " 'ADEIDA': 'F',\n",
       " 'ADIBA': 'F',\n",
       " 'ABIDAN': 'M',\n",
       " 'ABIDAO': 'M',\n",
       " 'ABIDENOR': 'M',\n",
       " 'ABIDERMAN': 'M',\n",
       " 'ABIDIAS': 'M',\n",
       " 'ABIDAL': 'M',\n",
       " 'ABIDEL': 'M',\n",
       " 'ABIDIEL': 'M',\n",
       " 'ABIDOM': 'M',\n",
       " 'ABIDON': 'M',\n",
       " 'ABIDORAL': 'M',\n",
       " 'ABIESER': 'M',\n",
       " 'ABIEZER': 'M',\n",
       " 'ABIGAEL': 'F',\n",
       " 'ABIGAIL': 'F',\n",
       " 'ABIGAL': 'F',\n",
       " 'ABIGUAIL': 'F',\n",
       " 'HABIGAIL': 'F',\n",
       " 'ABIGAI': 'F',\n",
       " 'ABIGAIR': 'F',\n",
       " 'ADIJAIR': 'F',\n",
       " 'ABIGAIU': 'F',\n",
       " 'ABILANE': 'F',\n",
       " 'ADAILANE': 'F',\n",
       " 'ADEILANE': 'F',\n",
       " 'ADELANE': 'F',\n",
       " 'ADILANE': 'F',\n",
       " 'ADLANE': 'F',\n",
       " 'ABILDE': 'F',\n",
       " 'ADAILDE': 'F',\n",
       " 'ADALBER': 'F',\n",
       " 'ADEILDE': 'F',\n",
       " 'ADILDE': 'F',\n",
       " 'ABELE': 'M',\n",
       " 'ABILE': 'M',\n",
       " 'ADAILE': 'M',\n",
       " 'ADELE': 'M',\n",
       " 'ADELER': 'M',\n",
       " 'ADIELE': 'M',\n",
       " 'ADILE': 'M',\n",
       " 'ADILER': 'M',\n",
       " 'ADLE': 'M',\n",
       " 'ADLER': 'M',\n",
       " 'HADLER': 'M',\n",
       " 'ABILENE': 'F',\n",
       " 'ABLENE': 'F',\n",
       " 'ADALENE': 'F',\n",
       " 'ADELENE': 'F',\n",
       " 'ADILENE': 'F',\n",
       " 'ADLENE': 'F',\n",
       " 'ABILIANE': 'F',\n",
       " 'ADALIANE': 'F',\n",
       " 'ADELAINE': 'F',\n",
       " 'ADELAYNE': 'F',\n",
       " 'ADELIANE': 'F',\n",
       " 'ADILAINE': 'F',\n",
       " 'ADILIANE': 'F',\n",
       " 'ADLAINE': 'F',\n",
       " 'ABIMAEL': 'M',\n",
       " 'ABIMAIL': 'M',\n",
       " 'ABIMAL': 'M',\n",
       " 'ABIMEL': 'M',\n",
       " 'ABYMAEL': 'M',\n",
       " 'ADIMAEL': 'M',\n",
       " 'ABIMAELE': 'F',\n",
       " 'ABIMAR': 'M',\n",
       " 'ADIMA': 'M',\n",
       " 'ADIMAR': 'M',\n",
       " 'ABIMELEQUE': 'M',\n",
       " 'ABINA': 'F',\n",
       " 'ADEINA': 'F',\n",
       " 'ADINA': 'F',\n",
       " 'ADINAR': 'F',\n",
       " 'ADYNA': 'F',\n",
       " 'ABINADA': 'M',\n",
       " 'ABINADAB': 'M',\n",
       " 'ABINADABE': 'M',\n",
       " 'ABINADABI': 'M',\n",
       " 'ABINAEL': 'M',\n",
       " 'ABINAL': 'M',\n",
       " 'ABINEL': 'M',\n",
       " 'ABINOEL': 'M',\n",
       " 'ADINAEL': 'M',\n",
       " 'ADINAL': 'M',\n",
       " 'ADINEL': 'M',\n",
       " 'ADINIL': 'M',\n",
       " 'ADINOEL': 'M',\n",
       " 'ABINAIR': 'F',\n",
       " 'ADINAI': 'F',\n",
       " 'ADINAIR': 'F',\n",
       " 'ABINALDO': 'M',\n",
       " 'ADINAILDO': 'M',\n",
       " 'ADINALDO': 'M',\n",
       " 'ADINILDO': 'M',\n",
       " 'ABINE': 'M',\n",
       " 'ABINER': 'M',\n",
       " 'ABYNER': 'M',\n",
       " 'ADEINE': 'M',\n",
       " 'ADINE': 'M',\n",
       " 'ADINER': 'M',\n",
       " 'HABINER': 'M',\n",
       " 'ABINOA': 'F',\n",
       " 'ABINOAM': 'M',\n",
       " 'ABINOAN': 'M',\n",
       " 'ADINOAN': 'M',\n",
       " 'ABIO': 'M',\n",
       " 'ADIO': 'M',\n",
       " 'ABIQUEILA': 'F',\n",
       " 'ABIRACI': 'F',\n",
       " 'ADIRACI': 'F',\n",
       " 'ABIRAN': 'M',\n",
       " 'ADIRAN': 'M',\n",
       " 'ABISAEL': 'M',\n",
       " 'ABIZAEL': 'M',\n",
       " 'ADISOL': 'M',\n",
       " 'ABISAGUE': 'F',\n",
       " 'ABIZAGUE': 'F',\n",
       " 'ABISAI': 'M',\n",
       " 'ABISAIR': 'M',\n",
       " 'ABIZAI': 'M',\n",
       " 'ABIZAIR': 'M',\n",
       " 'ADISIA': 'M',\n",
       " 'ADIZIA': 'M',\n",
       " 'ABISALAO': 'M',\n",
       " 'ABISMAEL': 'M',\n",
       " 'ABISON': 'M',\n",
       " 'ADEISOM': 'M',\n",
       " 'ADEISON': 'M',\n",
       " 'ADISOM': 'M',\n",
       " 'ADISON': 'M',\n",
       " 'ADIZON': 'M',\n",
       " 'ADYSON': 'M',\n",
       " 'HADISON': 'M',\n",
       " 'ABISSALAO': 'M',\n",
       " 'ABIUDE': 'F',\n",
       " 'ADEIUDE': 'F',\n",
       " 'ABKEILA': 'F',\n",
       " 'ABMAEL': 'M',\n",
       " 'ADMAEL': 'M',\n",
       " 'ADMIL': 'M',\n",
       " 'ABMAR': 'M',\n",
       " 'ADHMAR': 'M',\n",
       " 'ADMA': 'M',\n",
       " 'ADMAR': 'M',\n",
       " 'ABMARIO': 'M',\n",
       " 'ADMARIO': 'M',\n",
       " 'ABNA': 'F',\n",
       " 'ADNA': 'F',\n",
       " 'ADNAR': 'F',\n",
       " 'ADNNA': 'F',\n",
       " 'HADNA': 'F',\n",
       " 'ABNADAB': 'M',\n",
       " 'ABNADABE': 'M',\n",
       " 'ABNAEL': 'M',\n",
       " 'ABNEL': 'M',\n",
       " 'ABNOEL': 'M',\n",
       " 'ADNAEL': 'M',\n",
       " 'ADNEL': 'M',\n",
       " 'ADNIL': 'M',\n",
       " 'ADNOEL': 'M',\n",
       " 'ABNEI': 'M',\n",
       " 'ABNI': 'M',\n",
       " 'ABNIR': 'M',\n",
       " 'ADNEI': 'M',\n",
       " 'ADNEY': 'M',\n",
       " 'ADNI': 'M',\n",
       " 'ADNIR': 'M',\n",
       " 'ADNY': 'M',\n",
       " 'ABNALDO': 'M',\n",
       " 'ABNILDO': 'M',\n",
       " 'ADNAILDO': 'M',\n",
       " 'ADNALDO': 'M',\n",
       " 'ADNILDO': 'M',\n",
       " 'ABNOAM': 'F',\n",
       " 'ABNOAN': 'F',\n",
       " 'ABRAA': 'M',\n",
       " 'ADRA': 'M',\n",
       " 'ABRAAM': 'M',\n",
       " 'ABRAAN': 'M',\n",
       " 'ABRAHAM': 'M',\n",
       " 'ABRAHAN': 'M',\n",
       " 'ABRAM': 'M',\n",
       " 'ABRAN': 'M',\n",
       " 'ADRAN': 'M',\n",
       " 'AABRAO': 'M',\n",
       " 'ABRAAO': 'M',\n",
       " 'ABRAHAO': 'M',\n",
       " 'ABRAO': 'M',\n",
       " 'ABRHAO': 'M',\n",
       " 'ABRRAO': 'M',\n",
       " 'ADRAAO': 'M',\n",
       " 'ADRAO': 'M',\n",
       " 'HABRAAO': 'M',\n",
       " 'HABRAO': 'M',\n",
       " 'ABRAHIM': 'M',\n",
       " 'ABRAIM': 'M',\n",
       " 'ABRAIN': 'M',\n",
       " 'ADRIAM': 'M',\n",
       " 'ADRIAN': 'M',\n",
       " 'ADRIANN': 'M',\n",
       " 'ADRYAM': 'M',\n",
       " 'ADRYAN': 'M',\n",
       " 'ADRYANN': 'M',\n",
       " 'HADRIAN': 'M',\n",
       " 'HADRYAN': 'M',\n",
       " 'ABRAMO': 'M',\n",
       " 'ABRANTES': 'M',\n",
       " 'ABRELINA': 'F',\n",
       " 'ABRILINA': 'F',\n",
       " 'ADRELINA': 'F',\n",
       " 'ABRELINO': 'M',\n",
       " 'ABRILINO': 'M',\n",
       " 'ADRELINO': 'M',\n",
       " 'ABREU': 'M',\n",
       " 'ABSAEL': 'M',\n",
       " 'ABSAIL': 'M',\n",
       " 'ABSAI': 'M',\n",
       " 'ABSAIR': 'M',\n",
       " 'ABSALAO': 'M',\n",
       " 'ABSALON': 'M',\n",
       " 'ABSOLOM': 'M',\n",
       " 'ABSOLON': 'M',\n",
       " 'ABSON': 'M',\n",
       " 'ADSOM': 'M',\n",
       " 'ADSON': 'M',\n",
       " 'ADZON': 'M',\n",
       " 'HADSON': 'M',\n",
       " 'ABUD': 'M',\n",
       " 'ACACIA': 'F',\n",
       " 'AKACIA': 'F',\n",
       " 'ACACIO': 'M',\n",
       " 'AKACIO': 'M',\n",
       " 'ACADIO': 'M',\n",
       " 'ACAIO': 'M',\n",
       " 'ACARCIO': 'M',\n",
       " 'ACARI': 'M',\n",
       " 'ACARY': 'M',\n",
       " 'ACASIO': 'M',\n",
       " 'AKASIO': 'M',\n",
       " 'ACASSIA': 'F',\n",
       " 'AKASSIA': 'F',\n",
       " 'ACASSIANO': 'M',\n",
       " 'ACASSIO': 'M',\n",
       " 'AKASSIO': 'M',\n",
       " 'ACATIA': 'F',\n",
       " 'AKATIA': 'F',\n",
       " 'ACAUA': 'M',\n",
       " 'AKAUA': 'M',\n",
       " 'ACAUAN': 'M',\n",
       " 'AKAUAN': 'M',\n",
       " 'ACAZ': 'M',\n",
       " 'ACCACIO': 'M',\n",
       " 'ACEBIAS': 'M',\n",
       " 'ACEDINA': 'F',\n",
       " 'ACEDIR': 'M',\n",
       " 'ACEIR': 'M',\n",
       " 'ACI': 'M',\n",
       " 'ACIR': 'M',\n",
       " 'ACY': 'M',\n",
       " 'ACYR': 'M',\n",
       " 'AKI': 'M',\n",
       " 'ACEL': 'M',\n",
       " 'ACIEL': 'M',\n",
       " 'ACIL': 'M',\n",
       " 'ACIOL': 'M',\n",
       " 'AKEL': 'M',\n",
       " 'AKIL': 'M',\n",
       " 'ACELA': 'F',\n",
       " 'ACILA': 'F',\n",
       " 'ACLA': 'F',\n",
       " 'AKILA': 'F',\n",
       " 'AKLA': 'F',\n",
       " 'AKUILA': 'F',\n",
       " 'AKYLA': 'F',\n",
       " 'HAKILA': 'F',\n",
       " 'ACELI': 'F',\n",
       " 'ACELIR': 'F',\n",
       " 'ACELY': 'F',\n",
       " 'ACEOLI': 'F',\n",
       " 'ACIELI': 'F',\n",
       " 'ACIOLI': 'F',\n",
       " 'ACIOLY': 'F',\n",
       " 'ACLEI': 'F',\n",
       " 'AKELI': 'F',\n",
       " 'ACELIA': 'F',\n",
       " 'ACILIA': 'F',\n",
       " 'ACLAIR': 'F',\n",
       " 'ACELINA': 'F',\n",
       " 'ACILINA': 'F',\n",
       " 'ACIOLINA': 'F',\n",
       " 'ACELINE': 'F',\n",
       " 'AKELINE': 'F',\n",
       " 'ACELINO': 'M',\n",
       " 'ACILINO': 'M',\n",
       " 'ACIOLINO': 'M',\n",
       " 'ACYLINO': 'M',\n",
       " 'ACELIO': 'M',\n",
       " 'ACILIO': 'M',\n",
       " 'ACELMO': 'M',\n",
       " 'ACELON': 'M',\n",
       " 'ACILOM': 'M',\n",
       " 'ACILON': 'M',\n",
       " 'ACELSO': 'M',\n",
       " 'ACEMAR': 'M',\n",
       " 'ACEMIR': 'F',\n",
       " 'AKEMI': 'F',\n",
       " 'AKEMY': 'F',\n",
       " 'ACENATE': 'F',\n",
       " 'ACENDINA': 'F',\n",
       " 'ACENDINO': 'M',\n",
       " 'ACENI': 'M',\n",
       " 'ACENIR': 'M',\n",
       " 'AKENI': 'M',\n",
       " 'ACENIL': 'M',\n",
       " 'ACENILDA': 'F',\n",
       " 'ACENILDE': 'F',\n",
       " 'ACENILDO': 'M',\n",
       " 'ACENILTON': 'M',\n",
       " 'ACENO': 'M',\n",
       " 'ACENOR': 'M',\n",
       " 'ACER': 'M',\n",
       " 'ACETIDES': 'M',\n",
       " 'ACHILA': 'F',\n",
       " 'ASHILA': 'F',\n",
       " 'ACHILES': 'M',\n",
       " 'ACHELEY': 'F',\n",
       " 'ACHILEI': 'F',\n",
       " 'ACHILEY': 'F',\n",
       " 'ACHLEY': 'F',\n",
       " 'ASHALEY': 'F',\n",
       " 'ASHELEI': 'F',\n",
       " 'ASHELEY': 'F',\n",
       " 'ASHELY': 'F',\n",
       " 'ASHILEI': 'F',\n",
       " 'ASHILEY': 'F',\n",
       " 'ASHILY': 'F',\n",
       " 'ASHLEI': 'F',\n",
       " 'ASHLEY': 'F',\n",
       " 'ASHLY': 'F',\n",
       " 'ASHYLEI': 'F',\n",
       " 'ASHYLEY': 'F',\n",
       " 'ACHILIS': 'M',\n",
       " 'ACHILLE': 'M',\n",
       " 'ACHILLES': 'M',\n",
       " 'ACHYLLES': 'M',\n",
       " 'ACIARA': 'F',\n",
       " 'ACIDALHA': 'F',\n",
       " 'ACIDALIA': 'F',\n",
       " 'ACIDELIA': 'F',\n",
       " 'ACIDE': 'M',\n",
       " 'ACIDINO': 'M',\n",
       " 'ACIDIO': 'M',\n",
       " 'ACIELE': 'M',\n",
       " 'ACIOLE': 'M',\n",
       " 'ACIENE': 'F',\n",
       " 'ACILANE': 'F',\n",
       " 'ACILDA': 'F',\n",
       " 'ACILDO': 'M',\n",
       " 'ACILEA': 'F',\n",
       " 'ACILEIA': 'F',\n",
       " 'ACLEIA': 'F',\n",
       " 'ACILENE': 'F',\n",
       " 'ACILO': 'M',\n",
       " 'ACIMA': 'M',\n",
       " 'ACIMAR': 'M',\n",
       " 'ACINDINO': 'M',\n",
       " 'ACINEIDE': 'F',\n",
       " 'ACINELSON': 'M',\n",
       " 'ACINETE': 'F',\n",
       " 'ACINTIA': 'F',\n",
       " 'ACIO': 'M',\n",
       " 'AKIO': 'M',\n",
       " 'AKIYO': 'M',\n",
       " 'ACIOMAR': 'M',\n",
       " 'ACIONE': 'F',\n",
       " 'ACIONEIDE': 'F',\n",
       " 'ACIONEI': 'F',\n",
       " 'ACIONI': 'F',\n",
       " 'ACIONIR': 'F',\n",
       " 'ACIREMA': 'F',\n",
       " 'ACIRENE': 'F',\n",
       " 'ACIRES': 'M',\n",
       " 'AKIRES': 'M',\n",
       " 'ACIRIA': 'F',\n",
       " 'AKIRIA': 'F',\n",
       " 'ACIRIO': 'M',\n",
       " 'ACIRLENE': 'F',\n",
       " 'ACISA': 'F',\n",
       " 'AKISA': 'F',\n",
       " 'AKIZA': 'F',\n",
       " 'ACISIO': 'M',\n",
       " 'ACIVAL': 'M',\n",
       " 'ACIVALDO': 'M',\n",
       " 'ACKSON': 'M',\n",
       " 'ACLECIA': 'F',\n",
       " 'ACLECIANA': 'F',\n",
       " 'ACLECIANE': 'F',\n",
       " 'ACLECIANO': 'M',\n",
       " 'ACLECIO': 'M',\n",
       " 'ACLEDISON': 'M',\n",
       " 'ACLEDSON': 'M',\n",
       " 'ACILEIDE': 'F',\n",
       " 'ACLEIDE': 'F',\n",
       " 'ACLAILTON': 'M',\n",
       " 'ACLEILTON': 'M',\n",
       " 'ACLEITON': 'M',\n",
       " 'ACLES': 'M',\n",
       " 'AKILES': 'M',\n",
       " 'ACLESIA': 'F',\n",
       " 'ACLESIO': 'M',\n",
       " 'ACLEZIO': 'M',\n",
       " 'ACLIDES': 'M',\n",
       " 'ACLIMAR': 'M',\n",
       " 'ACLINIO': 'M',\n",
       " 'ACLIS': 'M',\n",
       " 'AKILIS': 'M',\n",
       " 'ACLISIO': 'M',\n",
       " 'ACRESIO': 'M',\n",
       " 'ACRICIA': 'F',\n",
       " 'ACRICIO': 'M',\n",
       " 'ACRINALDO': 'M',\n",
       " 'ACRISIA': 'F',\n",
       " 'ACRISIO': 'M',\n",
       " 'ACRIZIO': 'M',\n",
       " 'ACSA': 'F',\n",
       " 'ACZA': 'F',\n",
       " 'AKSA': 'F',\n",
       " 'AKZA': 'F',\n",
       " 'ACSEL': 'M',\n",
       " 'AKSEL': 'M',\n",
       " 'ACSIA': 'F',\n",
       " 'ACSON': 'M',\n",
       " 'AKSON': 'M',\n",
       " 'ACSSA': 'F',\n",
       " 'AKSSA': 'F',\n",
       " 'ACTON': 'M',\n",
       " 'ACUCENA': 'F',\n",
       " 'ACURCIO': 'M',\n",
       " 'ABADIL': 'M',\n",
       " 'ADABEL': 'M',\n",
       " 'ADACI': 'F',\n",
       " 'ADACIR': 'F',\n",
       " 'ADACY': 'F',\n",
       " 'ADACIA': 'F',\n",
       " 'HADACIA': 'F',\n",
       " 'ADACIEL': 'M',\n",
       " 'ADACIL': 'M',\n",
       " 'ADACILDA': 'F',\n",
       " 'ADACILDO': 'M',\n",
       " 'ADACIO': 'M',\n",
       " 'ADADILSON': 'M',\n",
       " 'ADAGIL': 'M',\n",
       " 'ADAGILDA': 'F',\n",
       " 'ADAGILSA': 'F',\n",
       " 'ADAGILZA': 'F',\n",
       " 'ADAJILSA': 'F',\n",
       " 'ADAJILZA': 'F',\n",
       " 'ADAGILSO': 'M',\n",
       " 'ADAGILZO': 'M',\n",
       " 'ADAGILSON': 'M',\n",
       " 'ADAJILSON': 'M',\n",
       " 'ADAGIR': 'M',\n",
       " 'ADAGMAR': 'F',\n",
       " 'ADAGOBERTO': 'M',\n",
       " 'ADAGUIMAR': 'F',\n",
       " 'ADAIA': 'F',\n",
       " 'ADAIANA': 'F',\n",
       " 'ADAYANA': 'F',\n",
       " 'ADAIANE': 'F',\n",
       " 'ADAYANE': 'F',\n",
       " 'ADAIAS': 'M',\n",
       " 'ADAIDE': 'F',\n",
       " 'ADAIDES': 'F',\n",
       " 'ADAIDO': 'M',\n",
       " 'ADAIENE': 'F',\n",
       " 'ADAILCE': 'F',\n",
       " 'ADEILCE': 'F',\n",
       " 'ADELCE': 'F',\n",
       " 'ADILCE': 'F',\n",
       " 'ADULCE': 'F',\n",
       " 'ADAILDA': 'F',\n",
       " 'ADEILDA': 'F',\n",
       " 'ADELBA': 'F',\n",
       " 'ADELBAR': 'F',\n",
       " 'ADILDA': 'F',\n",
       " 'ABILDES': 'F',\n",
       " 'ADAILDES': 'F',\n",
       " 'ADEILDES': 'F',\n",
       " 'ADAILSA': 'F',\n",
       " 'ADAILZA': 'F',\n",
       " 'ADEILSA': 'F',\n",
       " 'ADEILZA': 'F',\n",
       " 'ADELSA': 'F',\n",
       " 'ADELZA': 'F',\n",
       " 'ADILSA': 'F',\n",
       " 'ADILZA': 'F',\n",
       " 'ADAILSE': 'F',\n",
       " 'ADAILZE': 'F',\n",
       " 'ADEILSE': 'F',\n",
       " 'ADEILZE': 'F',\n",
       " 'ADILSE': 'F',\n",
       " 'ADILZE': 'F',\n",
       " 'ADAELSO': 'M',\n",
       " 'ADAILSO': 'M',\n",
       " 'ADAILZO': 'M',\n",
       " 'ADALSO': 'M',\n",
       " 'ADEILSO': 'M',\n",
       " 'ADEILZO': 'M',\n",
       " 'ADELSO': 'M',\n",
       " 'ADELZO': 'M',\n",
       " 'ADIELSO': 'M',\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importando dicionário de gêneros\n",
    "with open('aux/dicionario_generos.json', 'r') as f: \n",
    "    dicionario_generos = json.load(f)\n",
    "\n",
    "dicionario_generos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1f3a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a função auxiliar que será aplicada a cada nome completo\n",
    "def genero_baseado_no_primeiro_nome(nome_completo: str,\n",
    "                    dicionario_generos: dict) -> str:\n",
    "    \n",
    "    # Garante que é uma string, útil para lidar com NaNs ou outros tipos\n",
    "    nome_completo_str = str(nome_completo) \n",
    "    \n",
    "    primeiro_nome = nome_completo_str.split(' ')[0].strip().upper()\n",
    "    \n",
    "    # Usa .get() para retornar 'D' (Desconhecido) se o nome não for encontrado\n",
    "    return dicionario_generos.get(primeiro_nome, 'D')\n",
    "\n",
    "\n",
    "def adicionar_coluna_genero(df,\n",
    "                                 coluna_nome_completo: str, \n",
    "                                 dicionario_generos: dict,\n",
    "                                 coluna_genero: str = 'GN_PESSOA',\n",
    "                       ):\n",
    "    \"\"\"\n",
    "    Extrai o primeiro nome de uma coluna, consulta um dicionário de gêneros baseados em primeiros nomes\n",
    "    e retorna os gêneros correspondentes em uma nova coluna, usando df.apply().\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): O DataFrame de entrada.\n",
    "        coluna_nome_completo (str): O nome da coluna no DataFrame que contém os nomes completos.\n",
    "        dicionario_generos (dict): Um dicionário onde as chaves são os primeiros nomes (em maiúsculas)\n",
    "                                   e os valores são os gêneros ('F', 'M', 'Desconhecido', etc.).\n",
    "        coluna_genero (str): Nome da nova coluna com o genero inferido com base no primeiro nome. O padrão é 'GN_PESSOA'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: O DataFrame original com uma nova coluna .\n",
    "    \"\"\"\n",
    "    df[coluna_genero] = df[coluna_nome_completo].apply(genero_baseado_no_primeiro_nome, \n",
    "                                                       dicionario_generos=dicionario_generos)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23a0d4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório 'sucupira_painel' criado com sucesso ou já existente.\n"
     ]
    }
   ],
   "source": [
    "#Criando diretório de saída dos arquivos processados\n",
    "try:\n",
    "    # Cria o diretório\n",
    "    # 'exist_ok=True' é crucial: se o diretório já existir, ele não levantará um erro (FileExistsError)\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    print(f\"Diretório '{processed_dir}' criado com sucesso ou já existente.\")\n",
    "except OSError as e:\n",
    "    # Trata outros possíveis erros do sistema operacional (permissões, nomes inválidos, etc.)\n",
    "    print(f\"Erro ao criar o diretório '{processed_dir}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1950d0f",
   "metadata": {},
   "source": [
    "### Discentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60938756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AN_BASE</th>\n",
       "      <th>ID_PESSOA</th>\n",
       "      <th>CD_PROGRAMA_IES</th>\n",
       "      <th>NM_DISCENTE</th>\n",
       "      <th>DS_TIPO_NACIONALIDADE_DISCENTE</th>\n",
       "      <th>NM_PAIS_NACIONALIDADE_DISCENTE</th>\n",
       "      <th>AN_NASCIMENTO_DISCENTE</th>\n",
       "      <th>DS_GRAU_ACADEMICO_DISCENTE</th>\n",
       "      <th>ST_INGRESSANTE</th>\n",
       "      <th>NM_SITUACAO_DISCENTE</th>\n",
       "      <th>QT_MES_TITULACAO</th>\n",
       "      <th>SG_ENTIDADE_ENSINO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>3353229</td>\n",
       "      <td>31001017100P2</td>\n",
       "      <td>BRENDO ARAUJO GOMES</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>1994</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>SIM</td>\n",
       "      <td>MATRICULADO</td>\n",
       "      <td>0</td>\n",
       "      <td>UFRJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>26505</td>\n",
       "      <td>31001017033P3</td>\n",
       "      <td>CLAUDIA BENITEZ LOGELO</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>1973</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>MATRICULADO</td>\n",
       "      <td>0</td>\n",
       "      <td>UFRJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>1216819</td>\n",
       "      <td>31001017172P3</td>\n",
       "      <td>FRANCIANE PIMENTEL MELO</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>1974</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>MATRICULADO</td>\n",
       "      <td>0</td>\n",
       "      <td>UFRJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>794525</td>\n",
       "      <td>31001017020P9</td>\n",
       "      <td>GABRIELA MONTEZ HOLANDA DA SILVA</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>1990</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>NÃO</td>\n",
       "      <td>MATRICULADO</td>\n",
       "      <td>0</td>\n",
       "      <td>UFRJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>4485640</td>\n",
       "      <td>31001017134P4</td>\n",
       "      <td>DANIELLE BRODA DE VASCONCELLOS</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>1991</td>\n",
       "      <td>MESTRADO PROFISSIONAL</td>\n",
       "      <td>SIM</td>\n",
       "      <td>MATRICULADO</td>\n",
       "      <td>0</td>\n",
       "      <td>UFRJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AN_BASE  ID_PESSOA CD_PROGRAMA_IES                       NM_DISCENTE  \\\n",
       "0     2021    3353229   31001017100P2               BRENDO ARAUJO GOMES   \n",
       "1     2021      26505   31001017033P3            CLAUDIA BENITEZ LOGELO   \n",
       "2     2021    1216819   31001017172P3           FRANCIANE PIMENTEL MELO   \n",
       "3     2021     794525   31001017020P9  GABRIELA MONTEZ HOLANDA DA SILVA   \n",
       "4     2021    4485640   31001017134P4    DANIELLE BRODA DE VASCONCELLOS   \n",
       "\n",
       "  DS_TIPO_NACIONALIDADE_DISCENTE NM_PAIS_NACIONALIDADE_DISCENTE  \\\n",
       "0                     BRASILEIRO                         BRASIL   \n",
       "1                     BRASILEIRO                         BRASIL   \n",
       "2                     BRASILEIRO                         BRASIL   \n",
       "3                     BRASILEIRO                         BRASIL   \n",
       "4                     BRASILEIRO                         BRASIL   \n",
       "\n",
       "   AN_NASCIMENTO_DISCENTE DS_GRAU_ACADEMICO_DISCENTE ST_INGRESSANTE  \\\n",
       "0                    1994                  DOUTORADO            SIM   \n",
       "1                    1973                  DOUTORADO            NÃO   \n",
       "2                    1974                   MESTRADO            NÃO   \n",
       "3                    1990                  DOUTORADO            NÃO   \n",
       "4                    1991      MESTRADO PROFISSIONAL            SIM   \n",
       "\n",
       "  NM_SITUACAO_DISCENTE  QT_MES_TITULACAO SG_ENTIDADE_ENSINO  \n",
       "0          MATRICULADO                 0               UFRJ  \n",
       "1          MATRICULADO                 0               UFRJ  \n",
       "2          MATRICULADO                 0               UFRJ  \n",
       "3          MATRICULADO                 0               UFRJ  \n",
       "4          MATRICULADO                 0               UFRJ  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importando dados dos discentes\n",
    "discentes = pd.read_csv(f'{filtered_dir}/discentes.csv')\n",
    "discentes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64892056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NM_DISCENTE</th>\n",
       "      <th>GN_PESSOA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRENDO ARAUJO GOMES</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLAUDIA BENITEZ LOGELO</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FRANCIANE PIMENTEL MELO</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GABRIELA MONTEZ HOLANDA DA SILVA</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DANIELLE BRODA DE VASCONCELLOS</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        NM_DISCENTE GN_PESSOA\n",
       "0               BRENDO ARAUJO GOMES         M\n",
       "1            CLAUDIA BENITEZ LOGELO         F\n",
       "2           FRANCIANE PIMENTEL MELO         F\n",
       "3  GABRIELA MONTEZ HOLANDA DA SILVA         F\n",
       "4    DANIELLE BRODA DE VASCONCELLOS         F"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gerando a coluna de gênero com base no primeiro nome\n",
    "discentes = adicionar_coluna_genero(discentes,\n",
    "                        coluna_nome_completo='NM_DISCENTE',\n",
    "                        dicionario_generos=dicionario_generos)\n",
    "discentes[['NM_DISCENTE', 'GN_PESSOA']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73cbf347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo coluna ST_INGRESSANTE para booleano\n",
    "mapeamento_booleano = {'SIM': True, 'NÃO': False}\n",
    "discentes['ST_INGRESSANTE'] = discentes['ST_INGRESSANTE'].map(mapeamento_booleano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca6fbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mantendo apenas as colunas necessárias (que mudam ao longo do tempo)\n",
    "discentes_final_cols = ['AN_BASE', 'ID_PESSOA', 'CD_PROGRAMA_IES', 'DS_GRAU_ACADEMICO_DISCENTE', 'ST_INGRESSANTE', 'NM_SITUACAO_DISCENTE', 'QT_MES_TITULACAO']\n",
    "discentes_final = discentes[discentes_final_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6502c93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AN_BASE</th>\n",
       "      <th>ID_PESSOA</th>\n",
       "      <th>CD_PROGRAMA_IES</th>\n",
       "      <th>DS_GRAU_ACADEMICO_DISCENTE</th>\n",
       "      <th>ST_INGRESSANTE</th>\n",
       "      <th>NM_SITUACAO_DISCENTE</th>\n",
       "      <th>QT_MES_TITULACAO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>3353229</td>\n",
       "      <td>31001017100P2</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>True</td>\n",
       "      <td>MATRICULADO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>26505</td>\n",
       "      <td>31001017033P3</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>False</td>\n",
       "      <td>MATRICULADO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>1216819</td>\n",
       "      <td>31001017172P3</td>\n",
       "      <td>MESTRADO</td>\n",
       "      <td>False</td>\n",
       "      <td>MATRICULADO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>794525</td>\n",
       "      <td>31001017020P9</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>False</td>\n",
       "      <td>MATRICULADO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>4485640</td>\n",
       "      <td>31001017134P4</td>\n",
       "      <td>MESTRADO PROFISSIONAL</td>\n",
       "      <td>True</td>\n",
       "      <td>MATRICULADO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AN_BASE  ID_PESSOA CD_PROGRAMA_IES DS_GRAU_ACADEMICO_DISCENTE  \\\n",
       "0     2021    3353229   31001017100P2                  DOUTORADO   \n",
       "1     2021      26505   31001017033P3                  DOUTORADO   \n",
       "2     2021    1216819   31001017172P3                   MESTRADO   \n",
       "3     2021     794525   31001017020P9                  DOUTORADO   \n",
       "4     2021    4485640   31001017134P4      MESTRADO PROFISSIONAL   \n",
       "\n",
       "   ST_INGRESSANTE NM_SITUACAO_DISCENTE  QT_MES_TITULACAO  \n",
       "0            True          MATRICULADO                 0  \n",
       "1           False          MATRICULADO                 0  \n",
       "2           False          MATRICULADO                 0  \n",
       "3           False          MATRICULADO                 0  \n",
       "4            True          MATRICULADO                 0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizando dataframe final\n",
    "discentes_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e677669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando dataframe final\n",
    "discentes_final.to_csv(f'{processed_dir}/discentes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae208010",
   "metadata": {},
   "source": [
    "### Docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68cd12ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AN_BASE</th>\n",
       "      <th>ID_PESSOA</th>\n",
       "      <th>CD_PROGRAMA_IES</th>\n",
       "      <th>NM_DOCENTE</th>\n",
       "      <th>AN_NASCIMENTO_DOCENTE</th>\n",
       "      <th>DS_TIPO_NACIONALIDADE_DOCENTE</th>\n",
       "      <th>NM_PAIS_NACIONALIDADE_DOCENTE</th>\n",
       "      <th>DS_CATEGORIA_DOCENTE</th>\n",
       "      <th>DS_TIPO_VINCULO_DOCENTE_IES</th>\n",
       "      <th>DS_REGIME_TRABALHO</th>\n",
       "      <th>CD_CAT_BOLSA_PRODUTIVIDADE</th>\n",
       "      <th>NM_GRAU_TITULACAO</th>\n",
       "      <th>SG_ENTIDADE_ENSINO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>513065</td>\n",
       "      <td>31001017003P7</td>\n",
       "      <td>KATRIN GRIT GELFERT</td>\n",
       "      <td>1973</td>\n",
       "      <td>ESTRANGEIRO</td>\n",
       "      <td>ALEMANHA</td>\n",
       "      <td>PERMANENTE</td>\n",
       "      <td>SERVIDOR PÚBLICO</td>\n",
       "      <td>INTEGRAL</td>\n",
       "      <td>1C</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>UFRJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>173737</td>\n",
       "      <td>31001017003P7</td>\n",
       "      <td>SERGIO AUGUSTO ROMANA IBARRA</td>\n",
       "      <td>1984</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>PERMANENTE</td>\n",
       "      <td>SERVIDOR PÚBLICO</td>\n",
       "      <td>INTEGRAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>UFRJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>1129065</td>\n",
       "      <td>31001017003P7</td>\n",
       "      <td>ISAIA NISOLI</td>\n",
       "      <td>1982</td>\n",
       "      <td>ESTRANGEIRO</td>\n",
       "      <td>ITÁLIA</td>\n",
       "      <td>PERMANENTE</td>\n",
       "      <td>SERVIDOR PÚBLICO</td>\n",
       "      <td>INTEGRAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>UFRJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>939007</td>\n",
       "      <td>31001017003P7</td>\n",
       "      <td>SEYED HAMID HASSANZADEH HAFSHEJANI</td>\n",
       "      <td>1982</td>\n",
       "      <td>ESTRANGEIRO</td>\n",
       "      <td>IRÃ</td>\n",
       "      <td>PERMANENTE</td>\n",
       "      <td>SERVIDOR PÚBLICO</td>\n",
       "      <td>DEDICAÇÃO EXCLUSIVA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>UFRJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>535643</td>\n",
       "      <td>31001017003P7</td>\n",
       "      <td>LUCIANE QUOOS CONTE</td>\n",
       "      <td>1971</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>PERMANENTE</td>\n",
       "      <td>SERVIDOR PÚBLICO</td>\n",
       "      <td>INTEGRAL</td>\n",
       "      <td>1D</td>\n",
       "      <td>DOUTORADO</td>\n",
       "      <td>UFRJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AN_BASE  ID_PESSOA CD_PROGRAMA_IES                          NM_DOCENTE  \\\n",
       "0     2023     513065   31001017003P7                 KATRIN GRIT GELFERT   \n",
       "1     2023     173737   31001017003P7        SERGIO AUGUSTO ROMANA IBARRA   \n",
       "2     2023    1129065   31001017003P7                        ISAIA NISOLI   \n",
       "3     2023     939007   31001017003P7  SEYED HAMID HASSANZADEH HAFSHEJANI   \n",
       "4     2023     535643   31001017003P7                 LUCIANE QUOOS CONTE   \n",
       "\n",
       "   AN_NASCIMENTO_DOCENTE DS_TIPO_NACIONALIDADE_DOCENTE  \\\n",
       "0                   1973                   ESTRANGEIRO   \n",
       "1                   1984                    BRASILEIRO   \n",
       "2                   1982                   ESTRANGEIRO   \n",
       "3                   1982                   ESTRANGEIRO   \n",
       "4                   1971                    BRASILEIRO   \n",
       "\n",
       "  NM_PAIS_NACIONALIDADE_DOCENTE DS_CATEGORIA_DOCENTE  \\\n",
       "0                      ALEMANHA           PERMANENTE   \n",
       "1                        BRASIL           PERMANENTE   \n",
       "2                        ITÁLIA           PERMANENTE   \n",
       "3                           IRÃ           PERMANENTE   \n",
       "4                        BRASIL           PERMANENTE   \n",
       "\n",
       "  DS_TIPO_VINCULO_DOCENTE_IES   DS_REGIME_TRABALHO CD_CAT_BOLSA_PRODUTIVIDADE  \\\n",
       "0            SERVIDOR PÚBLICO             INTEGRAL                         1C   \n",
       "1            SERVIDOR PÚBLICO             INTEGRAL                        NaN   \n",
       "2            SERVIDOR PÚBLICO             INTEGRAL                        NaN   \n",
       "3            SERVIDOR PÚBLICO  DEDICAÇÃO EXCLUSIVA                        NaN   \n",
       "4            SERVIDOR PÚBLICO             INTEGRAL                         1D   \n",
       "\n",
       "  NM_GRAU_TITULACAO SG_ENTIDADE_ENSINO  \n",
       "0         DOUTORADO               UFRJ  \n",
       "1         DOUTORADO               UFRJ  \n",
       "2         DOUTORADO               UFRJ  \n",
       "3         DOUTORADO               UFRJ  \n",
       "4         DOUTORADO               UFRJ  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importando df filtrada\n",
    "docentes = pd.read_csv(f'{filtered_dir}/docentes.csv')\n",
    "docentes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61371cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NM_DOCENTE</th>\n",
       "      <th>GN_PESSOA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KATRIN GRIT GELFERT</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SERGIO AUGUSTO ROMANA IBARRA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISAIA NISOLI</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEYED HAMID HASSANZADEH HAFSHEJANI</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LUCIANE QUOOS CONTE</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           NM_DOCENTE GN_PESSOA\n",
       "0                 KATRIN GRIT GELFERT         F\n",
       "1        SERGIO AUGUSTO ROMANA IBARRA         M\n",
       "2                        ISAIA NISOLI         M\n",
       "3  SEYED HAMID HASSANZADEH HAFSHEJANI         D\n",
       "4                 LUCIANE QUOOS CONTE         F"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gerando a coluna de gênero com base no primeiro nome\n",
    "docentes = adicionar_coluna_genero(docentes,\n",
    "                        coluna_nome_completo='NM_DOCENTE',\n",
    "                        dicionario_generos=dicionario_generos)\n",
    "docentes[['NM_DOCENTE', 'GN_PESSOA']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6449da0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1C', nan, '1D', '1B', '1A', '2', 'SR'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#limpeza do campo CD_CAT_PRODUTIVIDADE\n",
    "docentes['CD_CAT_BOLSA_PRODUTIVIDADE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e515fb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1C', <NA>, '1D', '1B', '1A', '2'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docentes['CD_CAT_BOLSA_PRODUTIVIDADE'] = docentes['CD_CAT_BOLSA_PRODUTIVIDADE'].replace([np.nan, 'SR'], pd.NA)\n",
    "docentes['CD_CAT_BOLSA_PRODUTIVIDADE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65fd8a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PERMANENTE'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checando se só temos docentes permanentes\n",
    "docentes['DS_CATEGORIA_DOCENTE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2ecc4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mantendo apenas colunas necessárias (que mudam ao longo do tempo)\n",
    "docentes_final_cols = ['AN_BASE', 'ID_PESSOA', 'CD_PROGRAMA_IES', 'DS_TIPO_VINCULO_DOCENTE_IES', 'DS_REGIME_TRABALHO', 'CD_CAT_BOLSA_PRODUTIVIDADE', 'NM_GRAU_TITULACAO']\n",
    "docentes_final = docentes[docentes_final_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca4873a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AN_BASE</th>\n",
       "      <th>ID_PESSOA</th>\n",
       "      <th>CD_PROGRAMA_IES</th>\n",
       "      <th>DS_TIPO_VINCULO_DOCENTE_IES</th>\n",
       "      <th>DS_REGIME_TRABALHO</th>\n",
       "      <th>CD_CAT_BOLSA_PRODUTIVIDADE</th>\n",
       "      <th>NM_GRAU_TITULACAO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>513065</td>\n",
       "      <td>31001017003P7</td>\n",
       "      <td>SERVIDOR PÚBLICO</td>\n",
       "      <td>INTEGRAL</td>\n",
       "      <td>1C</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>173737</td>\n",
       "      <td>31001017003P7</td>\n",
       "      <td>SERVIDOR PÚBLICO</td>\n",
       "      <td>INTEGRAL</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>1129065</td>\n",
       "      <td>31001017003P7</td>\n",
       "      <td>SERVIDOR PÚBLICO</td>\n",
       "      <td>INTEGRAL</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>939007</td>\n",
       "      <td>31001017003P7</td>\n",
       "      <td>SERVIDOR PÚBLICO</td>\n",
       "      <td>DEDICAÇÃO EXCLUSIVA</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>535643</td>\n",
       "      <td>31001017003P7</td>\n",
       "      <td>SERVIDOR PÚBLICO</td>\n",
       "      <td>INTEGRAL</td>\n",
       "      <td>1D</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AN_BASE  ID_PESSOA CD_PROGRAMA_IES DS_TIPO_VINCULO_DOCENTE_IES  \\\n",
       "0     2023     513065   31001017003P7            SERVIDOR PÚBLICO   \n",
       "1     2023     173737   31001017003P7            SERVIDOR PÚBLICO   \n",
       "2     2023    1129065   31001017003P7            SERVIDOR PÚBLICO   \n",
       "3     2023     939007   31001017003P7            SERVIDOR PÚBLICO   \n",
       "4     2023     535643   31001017003P7            SERVIDOR PÚBLICO   \n",
       "\n",
       "    DS_REGIME_TRABALHO CD_CAT_BOLSA_PRODUTIVIDADE NM_GRAU_TITULACAO  \n",
       "0             INTEGRAL                         1C         DOUTORADO  \n",
       "1             INTEGRAL                       <NA>         DOUTORADO  \n",
       "2             INTEGRAL                       <NA>         DOUTORADO  \n",
       "3  DEDICAÇÃO EXCLUSIVA                       <NA>         DOUTORADO  \n",
       "4             INTEGRAL                         1D         DOUTORADO  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizando resultado final\n",
    "docentes_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f670b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando dataframe final\n",
    "docentes_final.to_csv(f'{processed_dir}/docentes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801d70d",
   "metadata": {},
   "source": [
    "### Pessoas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a83eeb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padronizar_nomes_colunas(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Renomeia colunas que terminam com '_DOCENTE' ou '_DISCENTE' para nomes padronizados.\n",
    "    Ex: 'AN_NASCIMENTO_DOCENTE' -> 'AN_NASCIMENTO'\n",
    "        'NM_PAIS_NACIONALIDADE_DISCENTE' -> 'NM_PAIS_NACIONALIDADE'\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): O DataFrame a ser renomeado.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: O DataFrame com as colunas renomeadas.\n",
    "    \"\"\"\n",
    "    novo_mapeamento = {}\n",
    "    for coluna in df.columns:\n",
    "        if coluna.endswith('_DOCENTE'):\n",
    "            novo_mapeamento[coluna] = coluna.replace('_DOCENTE', '')\n",
    "        elif coluna.endswith('_DISCENTE'):\n",
    "            novo_mapeamento[coluna] = coluna.replace('_DISCENTE', '')\n",
    "        else:\n",
    "            novo_mapeamento[coluna] = coluna # Mantém colunas sem sufixo inalteradas\n",
    "    \n",
    "    return df.rename(columns=novo_mapeamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padronizando nomes de colunas entre docentes e discentes e extraindo colunas da tabela 'pessoas'\n",
    "pessoas_cols = ['AN_BASE', 'ID_PESSOA', 'NM', 'AN_NASCIMENTO', 'DS_TIPO_NACIONALIDADE', 'NM_PAIS_NACIONALIDADE', 'GN_PESSOA']\n",
    "pessoas_docentes = padronizar_nomes_colunas(docentes)[pessoas_cols]\n",
    "pessoas_discentes = padronizar_nomes_colunas(discentes)[pessoas_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "510585ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pessoas = pd.concat([pessoas_discentes, pessoas_discentes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b03c087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AN_BASE</th>\n",
       "      <th>ID_PESSOA</th>\n",
       "      <th>NM</th>\n",
       "      <th>AN_NASCIMENTO</th>\n",
       "      <th>DS_TIPO_NACIONALIDADE</th>\n",
       "      <th>NM_PAIS_NACIONALIDADE</th>\n",
       "      <th>GN_PESSOA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>3353229</td>\n",
       "      <td>BRENDO ARAUJO GOMES</td>\n",
       "      <td>1994</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>26505</td>\n",
       "      <td>CLAUDIA BENITEZ LOGELO</td>\n",
       "      <td>1973</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>1216819</td>\n",
       "      <td>FRANCIANE PIMENTEL MELO</td>\n",
       "      <td>1974</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>794525</td>\n",
       "      <td>GABRIELA MONTEZ HOLANDA DA SILVA</td>\n",
       "      <td>1990</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>4485640</td>\n",
       "      <td>DANIELLE BRODA DE VASCONCELLOS</td>\n",
       "      <td>1991</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158386</th>\n",
       "      <td>2017</td>\n",
       "      <td>978622</td>\n",
       "      <td>RAIMUNDO GOMES BARBOSA</td>\n",
       "      <td>1956</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158387</th>\n",
       "      <td>2017</td>\n",
       "      <td>999691</td>\n",
       "      <td>OTAVIO CABRERA DE LEO</td>\n",
       "      <td>1975</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158388</th>\n",
       "      <td>2017</td>\n",
       "      <td>1001943</td>\n",
       "      <td>LETICIA VON KRUGER PIMENTEL</td>\n",
       "      <td>1973</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158389</th>\n",
       "      <td>2017</td>\n",
       "      <td>1030429</td>\n",
       "      <td>VERUSKA POBIKROWSKA TARDIVO</td>\n",
       "      <td>1977</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158390</th>\n",
       "      <td>2017</td>\n",
       "      <td>1030910</td>\n",
       "      <td>ELOANE DE JESUS RAMOS CANTUARIA</td>\n",
       "      <td>1972</td>\n",
       "      <td>BRASILEIRO</td>\n",
       "      <td>BRASIL</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316782 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AN_BASE  ID_PESSOA                                NM  AN_NASCIMENTO  \\\n",
       "0          2021    3353229               BRENDO ARAUJO GOMES           1994   \n",
       "1          2021      26505            CLAUDIA BENITEZ LOGELO           1973   \n",
       "2          2021    1216819           FRANCIANE PIMENTEL MELO           1974   \n",
       "3          2021     794525  GABRIELA MONTEZ HOLANDA DA SILVA           1990   \n",
       "4          2021    4485640    DANIELLE BRODA DE VASCONCELLOS           1991   \n",
       "...         ...        ...                               ...            ...   \n",
       "158386     2017     978622            RAIMUNDO GOMES BARBOSA           1956   \n",
       "158387     2017     999691             OTAVIO CABRERA DE LEO           1975   \n",
       "158388     2017    1001943       LETICIA VON KRUGER PIMENTEL           1973   \n",
       "158389     2017    1030429       VERUSKA POBIKROWSKA TARDIVO           1977   \n",
       "158390     2017    1030910   ELOANE DE JESUS RAMOS CANTUARIA           1972   \n",
       "\n",
       "       DS_TIPO_NACIONALIDADE NM_PAIS_NACIONALIDADE GN_PESSOA  \n",
       "0                 BRASILEIRO                BRASIL         M  \n",
       "1                 BRASILEIRO                BRASIL         F  \n",
       "2                 BRASILEIRO                BRASIL         F  \n",
       "3                 BRASILEIRO                BRASIL         F  \n",
       "4                 BRASILEIRO                BRASIL         F  \n",
       "...                      ...                   ...       ...  \n",
       "158386            BRASILEIRO                BRASIL         M  \n",
       "158387            BRASILEIRO                BRASIL         M  \n",
       "158388            BRASILEIRO                BRASIL         F  \n",
       "158389            BRASILEIRO                BRASIL         F  \n",
       "158390            BRASILEIRO                BRASIL         F  \n",
       "\n",
       "[316782 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pessoas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0ad14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pessoas_sem_duplicatas = pessoas.drop_duplicates(['ID_PESSOA', 'NM', 'AN_NASCIMENTO', 'DS_TIPO_NACIONALIDADE', 'NM_PAIS_NACIONALIDADE', 'GN_PESSOA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09262ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pessoas_sem_duplicatas['ID_PESSOA'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a2a8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara_duplicatas = pessoas_sem_duplicatas['ID_PESSOA'].duplicated(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91659fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pessoas_sem_duplicatas[mascara_duplicatas].sort_values(by='ID_PESSOA').to_csv(f'{processed_dir}/id_pessoa_dups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc600a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docentes.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(discentes.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7595d3f2",
   "metadata": {},
   "source": [
    "### Programas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09440b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando df filtrada\n",
    "programas = pd.read_csv(f'{filtered_dir}/programas.csv')\n",
    "programas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0afd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checando valores do campo 'IN_REDE'\n",
    "programas['IN_REDE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo valores para booleans\n",
    "mapeamento_booleano = {'SIM': True, 'NÃO': False}\n",
    "programas['IN_REDE'] = programas['IN_REDE'].map(mapeamento_booleano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdcd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "programas['IN_REDE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d2cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checando conceitos atribuídos às PPGs\n",
    "programas['CD_CONCEITO_PROGRAMA'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo conceito 'A' (provavelmente 'Ausente') para 0\n",
    "programas['CD_CONCEITO_PROGRAMA'] = programas['CD_CONCEITO_PROGRAMA'].replace('A', 0).astype('int') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe59349",
   "metadata": {},
   "outputs": [],
   "source": [
    "programas['CD_CONCEITO_PROGRAMA'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checando colunas ANO_INICIO_PROGRAMA e AN_INICIO_PROGRAMA \n",
    "print(programas[['ANO_INICIO_PROGRAMA', 'AN_INICIO_PROGRAMA']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd40da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fundindo colunas ANO_INICIO_PROGRAMA e AN_INICIO_PROGRAMA \n",
    "#'AN_INICIO_PROGRAMA' convertido para int para evitar a permanência de floats graças aos nan anteriores\n",
    "programas['AN_INICIO_PROGRAMA'] = programas['AN_INICIO_PROGRAMA'].fillna(programas['ANO_INICIO_PROGRAMA']).astype('int') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a5a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(programas[['ANO_INICIO_PROGRAMA', 'AN_INICIO_PROGRAMA']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25625c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo colunas desnecessárias\n",
    "programas_final = programas.drop(columns = ['ANO_INICIO_PROGRAMA', 'SG_ENTIDADE_ENSINO', 'AN_INICIO_CURSO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd0240",
   "metadata": {},
   "outputs": [],
   "source": [
    "programas_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa50959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando dataframe programas_final\n",
    "programas_final.to_csv(f'{processed_dir}/programas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24593d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_programa = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84baca53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d14412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agora, será necessário extrair a tabela 'cursos' de dentro da tabela 'programas'\n",
    "#Lembrando que alguns programas oferecem mestrado e doutorado simultaneamente\n",
    "# Logo, precisaremos de alguma lógica para lidar com isso\n",
    "print(f'Valores únicos: {programas['NM_GRAU_PROGRAMA'].unique()}')\n",
    "print()\n",
    "print(programas[['NM_GRAU_PROGRAMA', 'AN_INICIO_CURSO']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22144e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerador_tabela_cursos(\n",
    "    df_programas: pd.DataFrame,\n",
    "    coluna_id_programa: str = 'CD_PROGRAMA_IES', \n",
    "    coluna_grau: str = 'NM_GRAU_PROGRAMA',\n",
    "    coluna_ano: str = 'AN_INICIO_CURSO'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Desagrega programas que possuem graus combinados (ex: 'MESTRADO/DOUTORADO')\n",
    "    e anos de início correspondentes (ex: '1981/2001') em linhas separadas.\n",
    "\n",
    "    Após a desagregação, a função retorna um novo DataFrame contendo apenas\n",
    "    as colunas CD_PROGRAMA_IES (ou o nome fornecido), NM_GRAU_PROGRAMA (ou o nome fornecido),\n",
    "    e AN_INICIO_CURSO (ou o nome fornecido), com entradas duplicadas removidas.\n",
    "\n",
    "    Args:\n",
    "        df_programas (pd.DataFrame): O DataFrame de entrada.\n",
    "        coluna_id_programa (str): O nome da coluna que contém o código do programa (ex: 'CD_PROGRAMA_IES').\n",
    "        coluna_grau (str): O nome da coluna que contém o grau do programa (padrão: 'NM_GRAU_PROGRAMA').\n",
    "        coluna_ano (str): O nome da coluna que contém o ano de início do curso (padrão: 'AN_INICIO_CURSO').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Um novo DataFrame com as colunas especificadas, graus desagregados\n",
    "                      e entradas duplicadas removidas.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Se as colunas especificadas não existirem no DataFrame.\n",
    "    \"\"\"\n",
    "    # Garante que as colunas existem no DataFrame de entrada\n",
    "    colunas_necessarias = [coluna_id_programa, coluna_grau, coluna_ano]\n",
    "    for col in colunas_necessarias:\n",
    "        if col not in df_programas.columns:\n",
    "            raise ValueError(f\"A coluna '{col}' não foi encontrada no DataFrame. Verifique o nome da coluna.\")\n",
    "\n",
    "    # Trabalha em uma cópia para não modificar o DataFrame original\n",
    "    df_trabalho = df_programas.copy()\n",
    "\n",
    "    # Identifica as linhas que contêm '/' na coluna de grau especificada\n",
    "    mascara_combinados = df_trabalho[coluna_grau].str.contains('/', na=False)\n",
    "    programas_combinados = df_trabalho[mascara_combinados].copy()\n",
    "    programas_outros_graus = df_trabalho[~mascara_combinados].copy()\n",
    "\n",
    "    df_novas_linhas = pd.DataFrame() # DataFrame vazio para acumular as novas linhas geradas\n",
    "\n",
    "    if not programas_combinados.empty:\n",
    "        # Divide tanto a coluna de graus quanto a de anos, usando os nomes passados\n",
    "        graus_divididos = programas_combinados[coluna_grau].str.split('/', expand=True)\n",
    "        anos_divididos = programas_combinados[coluna_ano].str.split('/', expand=True)\n",
    "\n",
    "        # Itera sobre as possíveis \"partes\"\n",
    "        for i in range(max(len(graus_divididos.columns), len(anos_divididos.columns))):\n",
    "            nome_grau_parte = graus_divididos.get(i)\n",
    "            ano_curso_parte = anos_divididos.get(i)\n",
    "\n",
    "            if nome_grau_parte is not None and ano_curso_parte is not None:\n",
    "                df_parte = programas_combinados.copy()\n",
    "\n",
    "                df_parte[coluna_grau] = nome_grau_parte\n",
    "                df_parte[coluna_ano] = ano_curso_parte\n",
    "\n",
    "                df_novas_linhas = pd.concat([df_novas_linhas, df_parte], ignore_index=True)\n",
    "\n",
    "        df_novas_linhas = df_novas_linhas.dropna(subset=[coluna_ano])\n",
    "\n",
    "    # Concatena o DataFrame de programas sem combinação e as novas linhas geradas\n",
    "    programas_final_completo = pd.concat([programas_outros_graus, df_novas_linhas], ignore_index=True)\n",
    "\n",
    "    # --- Nova Lógica para selecionar colunas e remover duplicatas ---\n",
    "\n",
    "    # Seleciona apenas as colunas desejadas\n",
    "    df_resultado = programas_final_completo[[coluna_id_programa, coluna_grau, coluna_ano]].copy()\n",
    "\n",
    "    # Opcional: Converte a coluna de ano de início para tipo numérico\n",
    "    df_resultado[coluna_ano] = pd.to_numeric(\n",
    "        df_resultado[coluna_ano], errors='coerce'\n",
    "    ).astype('Int64') # Usando Int64 para aceitar nulos, como discutido anteriormente\n",
    "\n",
    "    # Remove entradas duplicadas com base nas três colunas\n",
    "    df_resultado.drop_duplicates(inplace=True)\n",
    "\n",
    "    return df_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72802fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursos = gerador_tabela_cursos(programas) #Pode usar a tabela inicial, já que ela vai ter todas as informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3199b72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9411d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "programas_fulltable = desagregar_graus_programa(programas_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb23c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "programas_fulltable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f5078",
   "metadata": {},
   "source": [
    "### Produção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c81079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando df filtrada\n",
    "producao = pd.read_csv(f'{filtered_dir}/producao.csv')\n",
    "producao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79dda5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "producao['NM_NIVEL_DISCENTE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5cfb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "producao[producao['NM_NIVEL_DISCENTE'] == 'DOUTORADO'][['TP_AUTOR', 'NM_NIVEL_DISCENTE']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
